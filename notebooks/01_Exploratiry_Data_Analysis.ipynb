{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKIPnkHYqCDG"
      },
      "source": [
        "## 01 Exploratory Data Analysis\n",
        "## Objetivo\n",
        "Realizar un análisis exploratorio de los datos (EDA) para entender las características del dataset y detectar patrones, anomalías y relaciones entre las variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv2BhhIvqCDJ"
      },
      "source": [
        "### **Organización de los Datos**\n",
        "El conjunto de datos consta de dos tablas fundamentales. En primer lugar, contamos con la \"Tabla de Transacciones\", que ofrece información detallada sobre cada transacción realizada. En segundo lugar, encontramos la \"Tabla de Identidad\", la cual proporciona datos cruciales relacionados con la conexión de red, incluyendo información como la dirección IP, proveedor de servicios de Internet (ISP), el uso de proxy, entre otros.\n",
        "\n",
        "Esta estructura dual del conjunto de datos permite una comprensión integral de las transacciones al incorporar tanto los detalles transaccionales como la identidad digital asociada, enriqueciendo así el análisis y la interpretación de la información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "v1V55yAqqCDL"
      },
      "outputs": [],
      "source": [
        "## Librerías\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "import numpy as np\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    \"\"\"\n",
        "    Reduce el uso de memoria de un DataFrame de pandas cambiando los tipos de datos de las columnas numéricas\n",
        "    a tipos más eficientes sin perder información.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): El DataFrame a optimizar.\n",
        "    verbose (bool): Si es True, imprime el uso de memoria antes y después de la optimización.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: El DataFrame optimizado.\n",
        "    \"\"\"\n",
        "    # Obtener el uso inicial de memoria\n",
        "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "\n",
        "            # Optimización para tipos de datos enteros\n",
        "            if pd.api.types.is_integer_dtype(df[col]):\n",
        "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "\n",
        "            # Optimización para tipos de datos flotantes\n",
        "            else:\n",
        "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    # Obtener el uso final de memoria\n",
        "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    if verbose:\n",
        "        print(f'Mem. usage decreased to {end_mem:.2f} Mb ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def calcular_porcentaje_fraude(df_train,col):\n",
        "    # Filtrar y copiar el DataFrame eliminando filas con valores nulos en col\n",
        "    df_filtered = df_train.dropna(subset=[col]).copy()\n",
        "    df_filtered[col] = df_filtered[col].astype(int)  # Convertir col a tipo entero\n",
        "\n",
        "    # Separar por fraude y no fraude\n",
        "    df_fraude = df_filtered[df_filtered['isFraud'] == 1]\n",
        "    df_no_fraude = df_filtered[df_filtered['isFraud'] == 0]\n",
        "\n",
        "    # Calcular el tamaño de cada grupo agrupando por col para fraude y no fraude\n",
        "    addr_fraude = df_fraude.groupby(col).size().reset_index(name='N° Registros_Fraude')\n",
        "    addr_no_fraude = df_no_fraude.groupby(col).size().reset_index(name='N° Registros_No_Fraude')\n",
        "\n",
        "    # Combinar los resultados en un DataFrame final\n",
        "    addr_resultado = pd.merge(addr_fraude, addr_no_fraude, on=col, how='outer').fillna(0)\n",
        "\n",
        "    # Calcular el porcentaje sobre el total de cada fila\n",
        "    addr_resultado['Porcentaje_Fraude %'] = round((addr_resultado['N° Registros_Fraude'] /\n",
        "                                                   (addr_resultado['N° Registros_Fraude'] + addr_resultado['N° Registros_No_Fraude'])) * 100, 2)\n",
        "    addr_resultado['Porcentaje_No_Fraude %'] = round((addr_resultado['N° Registros_No_Fraude'] /\n",
        "                                                      (addr_resultado['N° Registros_Fraude'] + addr_resultado['N° Registros_No_Fraude'])) * 100, 2)\n",
        "\n",
        "    # Ordenar el DataFrame por número de registros de fraude de manera descendente y mostrar los primeros 10 grupos\n",
        "    #addr_resultado_porcentaje_fraude = addr_resultado.sort_values(by='Porcentaje_Fraude %', ascending=False).head(10)\n",
        "\n",
        "    return addr_resultado\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XT6XYX-qsizj"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importamos las librerias a usar\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection'"
      ],
      "metadata": {
        "id": "8XqXVBXoqW8e",
        "outputId": "7fe609fa-eeac-4391-ed75-7ebcb3ee0753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "U629FwACqCDN",
        "outputId": "7f0d6c28-a64b-4738-f569-4a49b06fbbb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.3G\n",
            "drwx------ 2 root root 4.0K Jun 22 14:48 processed\n",
            "-rw------- 1 root root 5.8M Dec 12  2019 sample_submission.csv\n",
            "-rw------- 1 root root  25M Dec 12  2019 test_identity.csv\n",
            "-rw------- 1 root root 585M Dec 12  2019 test_transaction.csv\n",
            "-rw------- 1 root root  26M Dec 12  2019 train_identity.csv\n",
            "-rw------- 1 root root 652M Dec 12  2019 train_transaction.csv\n"
          ]
        }
      ],
      "source": [
        "## directorio de los datasets\n",
        "#data_dir = '../data/raw/ieee-fraud-detection'\n",
        "## Lista de los archivos descargados\n",
        "!ls -lh {data_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "xq7eMlGEqCDP",
        "outputId": "b19d0c9b-cf74-4c5a-9158-267ba5faf52c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_transaction.csv tiene 590541 líneas\n",
            "train_identity.csv tiene 144234 líneas\n",
            "test_transaction.csv tiene 506692 líneas\n",
            "test_identity.csv tiene 141908 líneas\n"
          ]
        }
      ],
      "source": [
        "\n",
        "files = ['train_transaction.csv', 'train_identity.csv', 'test_transaction.csv', 'test_identity.csv']\n",
        "\n",
        "for file in files:\n",
        "    file_path = os.path.join(data_dir, file)\n",
        "    with open(file_path, 'r') as f:\n",
        "        line_count = sum(1 for line in f)\n",
        "    print(f'{file} tiene {line_count} líneas')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC4GthxWqCDQ"
      },
      "source": [
        "**Observación:**\n",
        "\n",
        "Los datos de entrenamientos son más de un millon de registro, por lo tanto se toma una fracción de los registro de entrenamiento para este trabajo para facilitar el análisis y el entrenamiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3VbCVSmqCDQ"
      },
      "source": [
        "\n",
        "### **Características Categóricas - Tabla Identity**\n",
        "\n",
        "Las variables en esta tabla incluyen información de identidad, abarcando detalles de la conexión de red (IP, ISP, Proxy, etc.) y la firma digital (UA/navegador/sistema operativo/versión, etc.) asociada con las transacciones. Estos datos son recopilados por el sistema de protección contra fraudes de Vesta y socios de seguridad digital. (Los nombres de los campos están enmascarados y no se proporcionará un diccionario emparejado por razones de privacidad y acuerdo contractual).\n",
        "\n",
        "- DeviceType\n",
        "- DeviceInfo\n",
        "- id_12 - id_38\n",
        "\n",
        "Se realiza una fusión de ambas tablas para construir un único marco de datos. Además, procederemos a seleccionar una porción específica de este marco de datos, ya que, en esta primera fase del análisis, no es necesario utilizar todos los registros. Al final, emplearemos la totalidad de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61c6MsNSqCDQ"
      },
      "source": [
        "### Selección de Porción del Dataset con Muestreo Estratificado\n",
        "\n",
        "Para seleccionar una porción representativa de un dataset grande para entrenamiento sin introducir sesgo, se utiliza el muestreo aleatorio estratificado. Este método asegura que la proporción de clases en la muestra sea la misma que en el conjunto de datos original, lo cual es crucial para problemas de clasificación con clases desbalanceadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Cargamos los dataset de train_transaction y train_identity\n",
        "df_transaction_train = pd.read_csv(data_dir + '/train_transaction.csv')\n",
        "df_identity_train = pd.read_csv(data_dir + '/train_identity.csv')\n",
        "## Reducimos los tamaños de los dataset cambiando los tipos de los datos de las columnas\n",
        "df_transaction_train = reduce_mem_usage(df_transaction_train)\n",
        "df_identity_train = reduce_mem_usage(df_identity_train)"
      ],
      "metadata": {
        "id": "KX2RNXIBtUk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRm0tEMUqCDR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Combinar los datasets\n",
        "dataset = pd.merge(df_transaction_train, df_identity_train, on='TransactionID', how='left')\n",
        "df_train = dataset\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpfspUoIqCDS"
      },
      "source": [
        "### Dimensiones del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPc5hpfWqCDS"
      },
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hxWFP2bqCDT"
      },
      "source": [
        "## **Consideraciones Iniciales**\n",
        "En la fase inicial de nuestro análisis, nos enfrentamos a una abrumadora cantidad de columnas. Con el objetivo de simplificar y focalizarnos en esta etapa inicial, buscaremos reducir el conjunto de columnas al máximo posible.\n",
        "\n",
        "### Características Iniciales para el Análisis de Primera Etapa\n",
        "1. **TransactionDT:** Representa un delta de tiempo desde un punto de referencia.\n",
        "2. **TransactionAMT:** Indica la cantidad en USD para el pago de la transacción.\n",
        "3. **ProductCD:** Código del producto.\n",
        "4. **addr:** Dirección.\n",
        "5. **dist:** Distancia.\n",
        "6. **P_ and (R__):** Dominio de correo electrónico del comprador y del destinatario.\n",
        "7. **deviceType**\n",
        "8. **DeviceInfo**\n",
        "\n",
        "Las siguientes características no se incluirán en esta fase inicial:\n",
        "- **C1-C14:** Recuento, como la cantidad de direcciones asociadas a la tarjeta de pago, entre otros. El significado real está enmascarado.\n",
        "- **D1-D15:** Timedelta, como los días entre la transacción anterior, etc.\n",
        "- **M1-M9:** Coincidencias, como los nombres en la tarjeta y la dirección, etc.\n",
        "- **Vxxx:** Características ricas desarrolladas por Vesta, que incluyen ranking, conteo y relaciones con otras entidades.\n",
        "\n",
        "id_12 - id_38\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFAgIBvEqCDU"
      },
      "source": [
        "Por lo tanto tenemos 11 columnas de propiedades y 59054 registros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTlsZhTeqCDU"
      },
      "source": [
        "### Tipos de datos y resumen estadísticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkNpt5AtqCDV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que ya tienes cargado tu dataset en 'df_train'\n",
        "\n",
        "# Identificar tipos de datos\n",
        "data_types = df_train.drop('isFraud',axis=1).dtypes\n",
        "\n",
        "# Filtrar y contar variables numéricas y categóricas\n",
        "num_vars = data_types[data_types != 'object']  # Variables numéricas\n",
        "cat_vars = data_types[data_types == 'object']  # Variables categóricas\n",
        "\n",
        "# Obtener nombres de las variables\n",
        "num_vars_names = num_vars.index.tolist()\n",
        "cat_vars_names = cat_vars.index.tolist()\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Número de variables numéricas: {num_vars.shape[0]}\")\n",
        "print(f\"Nombres de variables numéricas: {num_vars_names}\")\n",
        "print()\n",
        "print(f\"Número de variables categóricas: {cat_vars.shape[0]}\")\n",
        "print(f\"Nombres de variables categóricas: {cat_vars_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrZxIGBiqCDW"
      },
      "outputs": [],
      "source": [
        "for columna in cat_vars_names :\n",
        "    print(f\"Columna: {columna}, el número de variables es: {df_train[columna].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3j8TpWcqCDX"
      },
      "source": [
        "## Análisis de valores nulos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIRXBXI2qCDX"
      },
      "source": [
        "### Identificación de valores nulos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaG8eeAhqCDY"
      },
      "source": [
        "### Porcentaje de valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b-9R8F0qCDY"
      },
      "outputs": [],
      "source": [
        "# Calcula el porcentaje de valores nulos para cada columna\n",
        "null_percentages = (df_train.isnull().sum() / len(dataset)) * 100\n",
        "\n",
        "# Define los rangos para los valores nulos\n",
        "ranges = [\n",
        "    (0, 10),\n",
        "    (10, 20),\n",
        "    (20, 30),\n",
        "    (30, 40),\n",
        "    (40, 50),\n",
        "    (50, 60),\n",
        "    (60, 70),\n",
        "    (70, 80),\n",
        "    (80, 90),\n",
        "    (90, 100)\n",
        "]\n",
        "\n",
        "# Agrupa las columnas en los rangos definidosa\n",
        "grouped_columns = {f'{r[0]}-{r[1]}%': [] for r in ranges}\n",
        "\n",
        "for column, percentage in null_percentages.items():\n",
        "    for r in ranges:\n",
        "        if r[0] <= percentage < r[1]:\n",
        "            grouped_columns[f'{r[0]}-{r[1]}%'].append(column)\n",
        "\n",
        "# Imprime los resultados\n",
        "for range_, columns in grouped_columns.items():\n",
        "    if columns:\n",
        "        print(f'Rango de valores nulos: {range_}')\n",
        "        print(f'Columnas: {columns}')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxclNLYxqCDa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Suponiendo que ya tienes cargado tu dataset en 'df_train'\n",
        "\n",
        "# Crear una nueva DataFrame booleano indicando valores nulos\n",
        "df_nulls = df_train.sample(frac=0.1).isnull()\n",
        "\n",
        "# Calcular la correlación entre los valores nulos\n",
        "corr_nulls = df_nulls.corr()\n",
        "\n",
        "# Obtener triángulo superior de la matriz de correlación (sin la diagonal principal)\n",
        "upper_triangle = corr_nulls.where(np.triu(np.ones(corr_nulls.shape), k=1).astype(bool))\n",
        "\n",
        "# Definir umbral de correlación\n",
        "threshold = 0.5\n",
        "\n",
        "# Filtrar pares de variables con correlación mayor que el umbral\n",
        "high_corr_pairs = upper_triangle[upper_triangle.abs() > threshold].stack().reset_index()\n",
        "high_corr_pairs.columns = ['Variable 1', 'Variable 2', 'Correlación']\n",
        "\n",
        "# Mostrar los pares de variables con alta correlación ordenados por la correlación\n",
        "high_corr_pairs_sorted = high_corr_pairs.sort_values(by='Correlación', ascending=False)\n",
        "print(high_corr_pairs_sorted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM4AA-FdqCDa"
      },
      "source": [
        "\n",
        "\n",
        "Las variables también muestran una alta correlación de datos nulos, reflejada en la gran cantidad de valores ausentes para cada variable, lo cual contribuye a un alto valor de correlación entre ellas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTwjK_8aqCDc"
      },
      "source": [
        "### Valores Duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwsMR7rHqCDc"
      },
      "outputs": [],
      "source": [
        "df_train[df_train.duplicated(keep=False)].count().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8A2LnWlqCDd"
      },
      "source": [
        "Debido a la baja presencia de valores duplicados, procederemos a eliminarlos del dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4FRZPt0qCDf"
      },
      "source": [
        "## Análisis Univariado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmtLY0iJqCDf"
      },
      "source": [
        "### Columna Target 'isFraud'\n",
        "\n",
        "Comenzamos el análisis focalizándonos en la columna \"isFraud\", ya que representa el resultado de nuestros predictores o características. Evaluamos la cantidad de registros y representaremos visualmente esta información mediante un gráfico de barras, con el propósito de ilustrar la cantidad de registros clasificados como fraude y aquellos que no lo son."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['isFraud'].value_counts()"
      ],
      "metadata": {
        "id": "RPTPqGLS1jmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhAPkm33qCDg"
      },
      "outputs": [],
      "source": [
        "# Calcular los números de fraudes en los datos de entrenamiento\n",
        "Numero_fraude = df_train.isFraud.value_counts()\n",
        "df_fraude = pd.DataFrame(Numero_fraude).rename(index={0: 'No', 1: 'Sí'})\n",
        "df_fraude.reset_index(inplace=True)\n",
        "df_fraude.columns = ['isFraud', 'count']  # Renombrar columnas para usar en seaborn\n",
        "\n",
        "# Crear la figura y el eje\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Crear el gráfico de barras\n",
        "sns.barplot(data=df_fraude, x='isFraud', y='count', palette=['tab:blue', 'tab:red'], ax=ax)\n",
        "\n",
        "# Etiquetas y título\n",
        "ax.set_ylabel('Número de Fraudes')\n",
        "ax.set_title('Número de Fraudes en los Datos de Entrenamiento')\n",
        "ax.set_xlabel('Es Fraude')\n",
        "\n",
        "# Añadir etiquetas a las barras\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Guardar la figura\n",
        "#plt.savefig(base_dir + 'balance_datos.png')\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk7mAhsKqCDg"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Calcular los porcentajes de fraudes en los datos de entrenamiento\n",
        "porcentaje_fraude = df_train['isFraud'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Crear un DataFrame con los porcentajes\n",
        "df_porcentaje_fraude = pd.DataFrame(porcentaje_fraude)\n",
        "\n",
        "# Renombrar las columnas\n",
        "df_porcentaje_fraude.columns = ['Porcentaje']\n",
        "\n",
        "# Restaurar los índices originales\n",
        "df_porcentaje_fraude.reset_index(inplace=True)\n",
        "\n",
        "# Renombrar las categorías\n",
        "df_porcentaje_fraude['isFraud'] = df_porcentaje_fraude['isFraud'].map({0: 'No', 1: 'Sí'})\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "df_porcentaje_fraude\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KCrexQTqCDh"
      },
      "source": [
        "Obervación:\n",
        "**Cantidad de registros por archivo**\n",
        "\n",
        "| Es Fraude | N° de Registros |\n",
        "| ------------ | ------------ |\n",
        "| No| 96,45%|\n",
        "| Sí| 3.54%|\n",
        "\n",
        "Se destaca que la mayoría abrumadora de las transacciones se encuentran en la categoría no fraudulenta, mientras que solo una fracción mínima corresponde a casos de fraude. Este desbalance en los datos puede representar un desafío significativo para el proceso de aprendizaje automático, ya que los modelos pueden tener dificultades para identificar y aprender patrones en las clases minoritarias debido a su escasez relativa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvXAEchyqCDh"
      },
      "source": [
        "### Análisis de las caracteterísticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDCvDYIqCDh"
      },
      "source": [
        "### Columna Importe del pago por transacción en USD (TransactionAmt)\n",
        "\n",
        "\n",
        "Analizamos la asociación entre la columna \"TransactionAmt\", que representa los importes de cada transacción, y la columna de fraude. Este análisis incluye la evaluación de la distribución de los montos en relación con la presencia de fraudes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiJ9fTQJqCDh"
      },
      "outputs": [],
      "source": [
        "df_train[['TransactionAmt']].describe().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFfMYVG4qCDi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(data=df_train, x='TransactionAmt')\n",
        "plt.ylabel('Número de Fraudes')\n",
        "plt.xlabel('USD')\n",
        "#plt.savefig(base_dir + 'trabs_total_box_plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN2nHVm3qCDi"
      },
      "source": [
        "El valor medio de la variable 'TransactionAmt' es de 134.5, con una desviación estándar de 263.63. Además, el valor máximo está considerablemente alejado del tercer quartil del 75%  de los datos, lo que indica la presencia de valores atípicos en esta característica, en el gráfico de arriba se pued apreciar con mas detalle la exitencia de valores atípicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_-h1j2pqCDi"
      },
      "outputs": [],
      "source": [
        "quartiles = np.percentile(df_train['TransactionAmt'], [25, 50, 75])\n",
        "mean_value = df_train['TransactionAmt'].mean()\n",
        "\n",
        "fig, axs = plt.subplots(tight_layout=True, figsize=(12, 8))\n",
        "\n",
        "# Crear el histograma\n",
        "sns.histplot(data=df_train, x='TransactionAmt', bins=100, color='tab:blue', edgecolor=\"white\", linewidth=0.7, label='No', log_scale=False, ax=axs)\n",
        "\n",
        "# Añadir líneas de los cuartiles\n",
        "for q in quartiles:\n",
        "    axs.axvline(q, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# Añadir línea de la media\n",
        "axs.axvline(mean_value, color='green', linestyle='-', linewidth=1)\n",
        "\n",
        "# Etiquetas y título\n",
        "axs.set_ylabel('Número de Fraudes')\n",
        "axs.set_xlabel('USD')\n",
        "\n",
        "# Añadir leyenda para los cuartiles y la media\n",
        "quartile_labels = ['Q1', 'Q2', 'Q3']\n",
        "for i, q in enumerate(quartiles):\n",
        "    axs.text(q, axs.get_ylim()[1] * 0.95, quartile_labels[i], color='red', ha='center', va='top')\n",
        "axs.text(mean_value, axs.get_ylim()[1] * 0.95, 'Mean', color='green', ha='center', va='top')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Gp9cUHqCDj"
      },
      "source": [
        "#### Vemos ahora estos valores en escala logarítmicas"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTPFxo7-3RD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función ECDF nos permite observar claramente las diferencias entre las distribuciones con y sin fraude. Se puede notar que la curva con fraude es más suave en comparación con la de no fraude, lo cual sugiere que esta diferencia podría ser una variable relevante para utilizar en el entrenamiento del modelo."
      ],
      "metadata": {
        "id": "nwGN1kS26GNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDzOb9E0qCDj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8gYjnut3HSNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_by_fraud = df_train.groupby('isFraud')['TransactionAmt'].describe().round(2)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(stats_by_fraud)"
      ],
      "metadata": {
        "id": "Ij03C5NtIN_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxyFdrfwqCDk"
      },
      "source": [
        "Observación:\n",
        "\n",
        "En la representación gráfica de la distribución y en la tabla de estadísticos asociada a la columna \"TransactionAmt\", se destacan las siguientes observaciones:\n",
        "\n",
        "- Se evidencia una notable disparidad de la mediana (Q2) con el valor medio de los valores de TransactionAmt.\n",
        "- El valor medio casi coincide con el los 75% de  valores (Q3) esto señale la gran dispersión de los valores.\n",
        "\n",
        "\n",
        "La comparación entre el límite superior del rango intercuartil y el valor máximo revela discrepancias significativas en órdenes de magnitud, indicando la presencia de datos atípicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl4EKiuTqCDk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Definir los rangos para 'TransactionAmt'\n",
        "ranges = [(0, 1000),(1000, df_train['TransactionAmt'].max())]\n",
        "\n",
        "# Crear la figura y los subplots\n",
        "fig, axs = plt.subplots(nrows=2, tight_layout=True, figsize=(12, 18))\n",
        "\n",
        "# Generar el histograma para cada rango\n",
        "for ax, (min_val, max_val) in zip(axs, ranges):\n",
        "    subset = df_train[(df_train['TransactionAmt'] >= min_val) & (df_train['TransactionAmt'] < max_val)]\n",
        "    sns.histplot(data=subset, x='TransactionAmt', bins=80, color='tab:blue', edgecolor=\"white\", linewidth=0.7, label='No', ax=ax, log_scale=True)\n",
        "    ax.set_title(f'TransactionAmt entre {min_val} y {max_val} USD')\n",
        "    ax.set_ylabel('Número de Fraudes')\n",
        "    ax.set_xlabel('USD')\n",
        "    # Añadir líneas de los cuartiles\n",
        "    for q in quartiles:\n",
        "        ax.axvline(q, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "    # Añadir línea de la media\n",
        "    ax.axvline(mean_value, color='green', linestyle='-', linewidth=1)\n",
        "\n",
        "    # Etiquetas y título\n",
        "    ax.set_ylabel('Número de Fraudes')\n",
        "    ax.set_xlabel('USD')\n",
        "\n",
        "    # Añadir leyenda para los cuartiles y la media\n",
        "    quartile_labels = ['Q1', 'Q2', 'Q3']\n",
        "    for i, q in enumerate(quartiles):\n",
        "        ax.text(q, ax.get_ylim()[1] * 0.95, quartile_labels[i], color='red', ha='center', va='top')\n",
        "    ax.text(mean_value, ax.get_ylim()[1] * 0.95, 'Mean', color='green', ha='center', va='top')\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edL0dMCfqCDl"
      },
      "source": [
        "Separamos el histograma en dos rangos de valores: uno de 0 a 1000 y otro de 1000 hasta el valor máximo. Al observar cada rango, notamos que presentan distribuciones diferentes, lo cual indica una posible segmentación en esta característica."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ecdf(data):\n",
        "    x = np.sort(data)\n",
        "    y = np.arange(1, len(data)+1) / len(data)\n",
        "    return x, y\n",
        "# Calcular ECDF para no fraude y fraude\n",
        "x_ecdf_no_fraude, y_ecdf_no_fraude = ecdf(df_train[df_train['isFraud'] == 0]['TransactionAmt'])\n",
        "x_ecdf_fraude, y_ecdf_fraude =ecdf(df_train[df_train['isFraud'] == 1]['TransactionAmt'])\n",
        "\n",
        "\n",
        "# Graficar ECDF\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Subplot 1: ECDF para No Fraude y Fraude juntos\n",
        "axs[0].plot(x_ecdf_no_fraude, y_ecdf_no_fraude, marker='.', linestyle='-', color='blue', label='No Fraude')\n",
        "axs[0].plot(x_ecdf_fraude, y_ecdf_fraude, marker='.', linestyle='-', color='red', label='Fraude')\n",
        "axs[0].set_xlabel('Valor')\n",
        "axs[0].set_ylabel('ECDF')\n",
        "axs[0].set_title('ECDF para No Fraude y Fraude')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Subplot 2: ECDF solo para No Fraude\n",
        "axs[1].plot(x_ecdf_no_fraude, y_ecdf_no_fraude, marker='.', linestyle='-', color='blue', label='No Fraude')\n",
        "axs[1].set_xlabel('Valor')\n",
        "axs[1].set_ylabel('ECDF')\n",
        "axs[1].set_title('ECDF para No Fraude')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Subplot 3: ECDF solo para Fraude\n",
        "axs[2].plot(x_ecdf_fraude, y_ecdf_fraude, marker='.', linestyle='-', color='red', label='Fraude')\n",
        "axs[2].set_xlabel('Valor')\n",
        "axs[2].set_ylabel('ECDF')\n",
        "axs[2].set_title('ECDF para Fraude')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ppNJbv7Iv8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Calcular cuartiles y media\n",
        "quartiles = np.percentile(df_train['TransactionAmt'], [25, 50, 75])\n",
        "mean_value = df_train['TransactionAmt'].mean()\n",
        "\n",
        "# Crear la figura y los ejes para ambos histogramas\n",
        "fig, axs = plt.subplots(1, 2, tight_layout=True, figsize=(16, 6))\n",
        "\n",
        "# Histograma para transacciones no fraudulentas\n",
        "sns.histplot(data=df_train[df_train['isFraud'] == 0], x='TransactionAmt', bins=100, color='tab:blue', edgecolor=\"white\", linewidth=0.7, label='No Fraude', log_scale=True, ax=axs[0])\n",
        "\n",
        "# Añadir líneas de los cuartiles para no fraude\n",
        "for q in quartiles:\n",
        "    axs[0].axvline(q, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# Añadir línea de la media para no fraude\n",
        "axs[0].axvline(mean_value, color='green', linestyle='-', linewidth=1)\n",
        "\n",
        "# Etiquetas y título para el primer histograma\n",
        "axs[0].set_ylabel('Número de Transacciones')\n",
        "axs[0].set_xlabel('USD')\n",
        "axs[0].set_title('Histograma de TransactionAmt - No Fraude')\n",
        "\n",
        "# Añadir leyenda para los cuartiles y la media en el primer histograma\n",
        "quartile_labels = ['Q1', 'Q2', 'Q3']\n",
        "for i, q in enumerate(quartiles):\n",
        "    axs[0].text(q, axs[0].get_ylim()[1] * 0.95, quartile_labels[i], color='red', ha='center', va='top')\n",
        "axs[0].text(mean_value, axs[0].get_ylim()[1] * 0.95, 'Mean', color='green', ha='center', va='top')\n",
        "\n",
        "# Histograma para transacciones fraudulentas\n",
        "sns.histplot(data=df_train[df_train['isFraud'] == 1], x='TransactionAmt', bins=100, color='tab:orange', edgecolor=\"white\", linewidth=0.7, label='Fraude', log_scale=True, ax=axs[1])\n",
        "\n",
        "# Añadir líneas de los cuartiles para fraude\n",
        "for q in quartiles:\n",
        "    axs[1].axvline(q, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# Añadir línea de la media para fraude\n",
        "axs[1].axvline(mean_value, color='green', linestyle='-', linewidth=1)\n",
        "\n",
        "# Etiquetas y título para el segundo histograma\n",
        "axs[1].set_ylabel('Número de Transacciones')\n",
        "axs[1].set_xlabel('USD')\n",
        "axs[1].set_title('Histograma de TransactionAmt - Fraude')\n",
        "\n",
        "# Añadir leyenda para los cuartiles y la media en el segundo histograma\n",
        "for i, q in enumerate(quartiles):\n",
        "    axs[1].text(q, axs[1].get_ylim()[1] * 0.95, quartile_labels[i], color='red', ha='center', va='top')\n",
        "axs[1].text(mean_value, axs[1].get_ylim()[1] * 0.95, 'Mean', color='green', ha='center', va='top')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rqf7TefrI04B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir los datos\n",
        "df_no_fraude = df_train[df_train['isFraud'] == 0]['TransactionAmt']\n",
        "df_fraude = df_train[df_train['isFraud'] == 1]['TransactionAmt']\n",
        "\n",
        "# Calcular cuartiles y media\n",
        "quartiles_no_fraude = np.percentile(df_no_fraude, [25, 50, 75])\n",
        "mean_value_no_fraude = df_no_fraude.mean()\n",
        "\n",
        "quartiles_fraude = np.percentile(df_fraude, [25, 50, 75])\n",
        "mean_value_fraude = df_fraude.mean()\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Histograma para transacciones no fraudulentas (normalizado)\n",
        "plt.hist(df_no_fraude, bins=100, color='tab:blue', edgecolor=\"white\", linewidth=0.7, label='No Fraude', log=True, density=True, alpha=0.7)\n",
        "\n",
        "# Añadir líneas de los cuartiles para no fraude\n",
        "for q in quartiles_no_fraude:\n",
        "    ax.axvline(q, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# Añadir línea de la media para no fraude\n",
        "ax.axvline(mean_value_no_fraude, color='green', linestyle='-', linewidth=1)\n",
        "\n",
        "# Histograma para transacciones fraudulentas (normalizado)\n",
        "plt.hist(df_fraude, bins=100, color='tab:orange', edgecolor=\"white\", linewidth=0.7, label='Fraude', log=True, density=True, alpha=0.7)\n",
        "\n",
        "# Añadir líneas de los cuartiles para fraude\n",
        "for q in quartiles_fraude:\n",
        "    ax.axvline(q, color='purple', linestyle='--', linewidth=1)\n",
        "\n",
        "# Añadir línea de la media para fraude\n",
        "ax.axvline(mean_value_fraude, color='black', linestyle='-', linewidth=1)\n",
        "\n",
        "# Etiquetas y título\n",
        "ax.set_ylabel('Densidad')\n",
        "ax.set_xlabel('USD')\n",
        "ax.set_title('Histograma de TransactionAmt - Comparación de Fraude y No Fraude')\n",
        "\n",
        "# Añadir leyenda para los cuartiles y la media\n",
        "quartile_labels = ['Q1', 'Q2', 'Q3']\n",
        "ax.text(mean_value_no_fraude, ax.get_ylim()[1] * 0.95, 'Mean No Fraude', color='green', ha='center', va='top')\n",
        "ax.text(mean_value_fraude, ax.get_ylim()[1] * 0.95, 'Mean Fraude', color='black', ha='center', va='top')\n",
        "for i, q in enumerate(quartiles_no_fraude):\n",
        "    ax.text(q, ax.get_ylim()[1] * 0.95, quartile_labels[i], color='red', ha='center', va='top')\n",
        "for i, q in enumerate(quartiles_fraude):\n",
        "    ax.text(q, ax.get_ylim()[1] * 0.95, quartile_labels[i], color='purple', ha='center', va='top')\n",
        "\n",
        "# Mostrar la leyenda y ajustar el gráfico\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QWmw_jxjI7DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_by_fraud = df_train.groupby('isFraud')['TransactionAmt'].describe().round(2)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(stats_by_fraud)"
      ],
      "metadata": {
        "id": "7MLgPv4fJCY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- El valor máximo de transacciones fraudulentas es de 5192. Por lo tanto, procederemos a filtrar nuestro DataFrame utilizando este umbral como punto de corte."
      ],
      "metadata": {
        "id": "luYDMI0CJFgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train[df_train['TransactionAmt'] < 5192]"
      ],
      "metadata": {
        "id": "E1EykSdWJZro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_by_fraud = df_train.groupby('isFraud')['TransactionAmt'].describe().round(2)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(stats_by_fraud)"
      ],
      "metadata": {
        "id": "Q26s1GOWOrH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu7-8BwFqCDl"
      },
      "source": [
        "### Separación de los datos por rango de la columna de (TransactionAmt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxP-TNxsqCDm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calcular los cuartiles y el IQR\n",
        "Q1 = np.percentile(df_train['TransactionAmt'], 25)\n",
        "Q3 = np.percentile(df_train['TransactionAmt'], 75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Definir los umbrales para valores atípicos\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Función para clasificar los valores en rangos\n",
        "def classify_transaction_amt(value):\n",
        "    if value < lower_bound:\n",
        "        return 'Muy bajo'\n",
        "    elif lower_bound <= value < Q1:\n",
        "        return 'Bajo'\n",
        "    elif Q1 <= value < Q3:\n",
        "        return 'Medio'\n",
        "    elif Q3 <= value < upper_bound:\n",
        "        return 'Alto'\n",
        "    else:\n",
        "        return 'Muy alto'\n",
        "\n",
        "# Aplicar la función de clasificación a la columna\n",
        "df_train['TransactionAmt_Range'] = df_train['TransactionAmt'].apply(classify_transaction_amt)\n",
        "\n",
        "# Mostrar algunos resultados\n",
        "print(df_train['TransactionAmt_Range'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezTbeBiDqCDm"
      },
      "outputs": [],
      "source": [
        "quartiles = np.percentile(df_train['TransactionAmt'], [25, 50, 75])\n",
        "mean_value = df_train['TransactionAmt'].mean()\n",
        "\n",
        "fig, axs = plt.subplots(tight_layout=True, figsize=(12, 8))\n",
        "\n",
        "# Crear el histograma\n",
        "sns.histplot(data=df_train, x='TransactionAmt', bins=100, color='tab:blue',\n",
        "             edgecolor=\"white\", linewidth=0.7, label='No', log_scale=True, ax=axs,hue='TransactionAmt_Range')\n",
        "\n",
        "# Añadir líneas de los cuartiles\n",
        "for q in quartiles:\n",
        "    axs.axvline(q, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# Añadir línea de la media\n",
        "axs.axvline(mean_value, color='green', linestyle='-', linewidth=1)\n",
        "\n",
        "# Etiquetas y título\n",
        "axs.set_ylabel('Número de Fraudes')\n",
        "axs.set_xlabel('USD')\n",
        "\n",
        "# Añadir leyenda para los cuartiles y la media\n",
        "quartile_labels = ['Q1', 'Q2', 'Q3']\n",
        "for i, q in enumerate(quartiles):\n",
        "    axs.text(q, axs.get_ylim()[1] * 0.95, quartile_labels[i], color='red', ha='center', va='top')\n",
        "axs.text(mean_value, axs.get_ylim()[1] * 0.95, 'Mean', color='green', ha='center', va='top')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEyYAWaPqCDn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Crear subplots para cada rango de valor\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10), sharey=False, tight_layout=True)\n",
        "\n",
        "# Definir los nombres de los rangos y los colores correspondientes\n",
        "range_labels = ['Muy bajo', 'Bajo', 'Medio', 'Alto']\n",
        "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
        "\n",
        "# Iterar sobre los subplots y los rangos\n",
        "for i, ax in enumerate(axs.flatten()):\n",
        "    range_label = range_labels[i]\n",
        "    color = colors[i]\n",
        "\n",
        "    # Filtrar datos para el rango actual\n",
        "    subset_data = df_train[df_train['TransactionAmt_Range'] == range_label]\n",
        "\n",
        "    # Verificar si hay datos en el subset\n",
        "    if not subset_data.empty:\n",
        "        # Calcular el número de transacciones en el rango actual\n",
        "        num_transactions = len(subset_data)\n",
        "\n",
        "        # Crear el histograma para el rango actual\n",
        "        sns.histplot(data=subset_data, x='TransactionAmt', bins=30, color=color,\n",
        "                     edgecolor=\"white\", linewidth=0.7, log_scale=True, ax=ax)\n",
        "\n",
        "        ax.set_ylim(bottom=0)\n",
        "\n",
        "    # Etiquetas y título para cada subplot\n",
        "    ax.set_title(f'Transaction Amount Range: {range_label}')\n",
        "    ax.set_xlabel('Transaction Amount (USD)')\n",
        "    ax.set_ylabel('Number of Transactions')\n",
        "\n",
        "# Ajustar el espacio entre subplots y mostrar la figura\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jmx7Im9qCDn"
      },
      "source": [
        "- Cada valor en la columna TransactionAmt se clasifica en uno de los rangos definidos (Muy bajo, Bajo, Medio, Alto, Muy alto) según los cuartiles y los límites de valores atípicos. Se crea una nueva columna llamada TransactionAmt_Range en el DataFrame, que contiene el rango correspondiente para cada valor de TransactionAmt.\n",
        "- No hay datos clasificados en la categoría \"Muy Bajo\".\n",
        "- La columna TransactionAmt será reemplazada por TransactionAmt_Range ya que ambas contienen esencialmente la misma información. La columna TransactionAmt tiene valores que varían considerablemente entre diferentes rangos, lo cual dificultaría la normalización y complicaría el entrenamiento de los modelos. Por lo tanto, TransactionAmt será eliminada y reemplazada por TransactionAmt_Range que tiene las categorías separadas por rangos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpKIA0o1qCDo"
      },
      "source": [
        "### Columna Intervalo de tiempo (**TransactionDT**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTRtQOX_qCDo"
      },
      "source": [
        "**TransactionDT**: timedelta desde una fecha de referencia dada (no es una marca de tiempo real).\n",
        "- \"El primer valor de TransactionDT es 86400, que corresponde al número de segundos en un día (60 * 60 * 24 = 86400), por lo que creo que la unidad es segundos. Usando esto, sabemos que los datos abarcan 6 meses, ya que el valor máximo es 15811131, lo que correspondería al día 183.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ2eVjv3qCDp"
      },
      "outputs": [],
      "source": [
        "df_train[['TransactionDT']].describe().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8PAKmaGqCDp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(data=df_train, x='TransactionDT')\n",
        "plt.ylabel('Número de Fraudes')\n",
        "plt.xlabel('Tiempo (Seg)')\n",
        "#plt.savefig(base_dir + 'trabs_total_box_plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ2LEx9jqCDq"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(tight_layout=True, figsize=(12, 8))\n",
        "\n",
        "sns.histplot(data=df_train, x='TransactionDT', bins=80, color='tab:blue', edgecolor=\"white\", linewidth=0.7, label='No')\n",
        "axs.set_ylabel('Número de Fraudes')\n",
        "axs.set_xlabel('Tiempo (Seg)')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS6UA8hzqCDq"
      },
      "source": [
        "**Observación:** La distribución de los tiempo de transacción es casi uniforme, aunuque se observa que algunos tiempo de transacciones son más frecuente que otros."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convertiendo 'TransactionDT' en unidades de tiempo"
      ],
      "metadata": {
        "id": "ZMna-b2821Cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "START_DATE = '2017-12-01'\n",
        "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
        "\n",
        "# Suponiendo que df_train tiene las columnas 'TransactionDT'\n",
        "df_train[\"Date\"] = df_train['TransactionDT'].apply(lambda x: startdate + datetime.timedelta(seconds=x))\n",
        "\n",
        "# Crear un DataFrame con las nuevas columnas a agregar\n",
        "new_columns = pd.DataFrame({\n",
        "    '_Weekdays': df_train['Date'].dt.dayofweek,\n",
        "    '_Hours': df_train['Date'].dt.hour,\n",
        "    '_Days': df_train['Date'].dt.day\n",
        "})\n",
        "\n",
        "# Unir todas las columnas al DataFrame original\n",
        "df_train = pd.concat([df_train, new_columns], axis=1)\n",
        "df_train['_Weekdays'] =df_train['_Weekdays'].astype('object')\n",
        "df_train['_Hours'] = df_train['_Hours'].astype('object')\n",
        "df_train['_Days'] = df_train['_Days'].astype('object')\n",
        "\n",
        "df_train.head(3)\n"
      ],
      "metadata": {
        "id": "PEfZp_wb298u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcular_porcentaje_fraude(df_train,'_Weekdays')"
      ],
      "metadata": {
        "id": "0BqTRJU6Ml7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcular_porcentaje_fraude(df_train,'_Days') code"
      ],
      "metadata": {
        "id": "8nL-ZZcWNekq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcular_porcentaje_fraude(df_train,'_Hours')"
      ],
      "metadata": {
        "id": "aiid72guOxMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Crear subplots para los gráficos de barras\n",
        "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 15))\n",
        "\n",
        "# Gráfico para _Weekdays\n",
        "sns.countplot(x='_Weekdays', data=df_train,hue='isFraud', ax=axes[0])\n",
        "axes[0].set_title('Distribución de transacciones por día de la semana', fontsize=14)\n",
        "axes[0].set_xlabel('Día de la semana')\n",
        "axes[0].set_ylabel('Número de transacciones')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Gráfico para _Hours\n",
        "sns.countplot(x='_Hours', data=df_train,hue='isFraud', ax=axes[1])\n",
        "axes[1].set_title('Distribución de transacciones por hora del día', fontsize=14)\n",
        "axes[1].set_xlabel('Hora del día')\n",
        "axes[1].set_ylabel('Número de transacciones')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Gráfico para _Days\n",
        "sns.countplot(x='_Days', data=df_train,hue='isFraud', ax=axes[2])\n",
        "axes[2].set_title('Distribución de transacciones por día del mes', fontsize=14)\n",
        "axes[2].set_xlabel('Día del mes')\n",
        "axes[2].set_ylabel('Número de transacciones')\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Ajustar el espaciado entre subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar los gráficos\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pg5F6qI-KkpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- No hay un día de la semana con un porcentaje significativamente mayor de fraude.\n",
        "- De manera similar, a lo largo del mes, no se observa un día con un porcetaje notablemente mayor de transacciones fraudulentas,.\n",
        "- Las transacciones al inicio y al final de día aumenta, aumentando así las cantidades de fraude también, pero a mitad del día los porcentaje de fraude aumenta ya que el número de transacciones disminuye, es decir la actidad fraudalente no sigue el comportamiento de las trasacciones de no fraude."
      ],
      "metadata": {
        "id": "n8FUG6g4PcTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Suponiendo que tienes un DataFrame df_train con la columna 'Date' formateada correctamente\n",
        "# y las columnas 'isFraud' que indica si es fraude o no.\n",
        "\n",
        "# Calcular el número total de transacciones por día\n",
        "total_transactions_by_day = df_train.groupby(df_train['Date'].dt.date).size()\n",
        "\n",
        "# Calcular el número de fraudes y no fraudes por día\n",
        "fraud_by_day = df_train[df_train['isFraud'] == 1].groupby(df_train['Date'].dt.date).size() / total_transactions_by_day\n",
        "fraud_no_by_day = df_train[df_train['isFraud'] == 0].groupby(df_train['Date'].dt.date).size() / total_transactions_by_day\n",
        "\n",
        "# Graficar la serie temporal normalizada\n",
        "fig, ax1 = plt.subplots(figsize=(18, 6))\n",
        "\n",
        "# Línea para fraudes (eje y izquierdo)\n",
        "sns.lineplot(x=fraud_by_day.index, y=fraud_by_day.values, marker='o', ax=ax1, label='Fraudes')\n",
        "ax1.set_xlabel('Fecha')\n",
        "ax1.set_ylabel('Proporción de fraudes', color='tab:blue')\n",
        "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Crear un segundo eje y (eje y derecho) para los no fraudes\n",
        "ax2 = ax1.twinx()\n",
        "sns.lineplot(x=fraud_no_by_day.index, y=fraud_no_by_day.values, marker='o', ax=ax2, color='red', label='No Fraudes')\n",
        "ax2.set_ylabel('Proporción de no fraudes', color='red')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "# Título y ajustes generales\n",
        "plt.title('Proporción de fraudes y no fraudes por día')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Bcx9OwRDTBiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Se puede observar que hay períodos donde el aumento de la actividad fraudulenta no se correlaciona con la actividad no fraudulenta. Pero en general parecen estar correlacionadas."
      ],
      "metadata": {
        "id": "o6fS1151TX1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "719zUN8f2wHd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOczIQJ7qCDr"
      },
      "source": [
        "### Columna ProductCD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tALsioMKqCDr"
      },
      "source": [
        "**ProductCD**: código de producto, el producto para cada transacción.\n",
        "- \"El producto no necesariamente tiene que ser un 'producto' real (como un artículo para agregar al carrito de compras). Podría ser cualquier tipo de servicio.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCb0avVVqCDs"
      },
      "outputs": [],
      "source": [
        "df_train['ProductCD'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Supongamos que ya tienes df_train y 'ProductCD' está presente en tus datos\n",
        "\n",
        "# Calcular el porcentaje de cada categoría en ProductCD\n",
        "productCD_percent = round((df_train['ProductCD'].value_counts() / len(df_train['ProductCD'])) * 100, 2)\n",
        "\n",
        "# Crear la figura y los ejes para los gráficos\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# Graficar el countplot de ProductCD desglosado por isFraud\n",
        "sns.countplot(data=df_train, x='ProductCD', hue='isFraud', palette='Set2', ax=axes[0])\n",
        "axes[0].set_title('Countplot de ProductCD desglosado por isFraud', fontsize=18)\n",
        "axes[0].set_xlabel('ProductCD', fontsize=14)\n",
        "axes[0].set_ylabel('Count', fontsize=14)\n",
        "axes[0].legend(title='isFraud')\n",
        "\n",
        "# Ajustar el formato de las etiquetas del eje x para mejorar la legibilidad\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Graficar el barplot de porcentaje de ProductCD\n",
        "sns.barplot(x=productCD_percent.index, y=productCD_percent.values, palette='tab10', ax=axes[1])\n",
        "axes[1].set_title('Porcentaje de ProductCD', fontsize=18)\n",
        "axes[1].set_xlabel('ProductCD', fontsize=14)\n",
        "axes[1].set_ylabel('%', fontsize=14)\n",
        "\n",
        "# Añadir etiquetas de porcentaje en las barras\n",
        "for p in axes[1].patches:\n",
        "    axes[1].annotate(f'{p.get_height()}%', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=12, color='black', xytext=(0, 5), textcoords='offset points')\n",
        "\n",
        "# Ajustar el formato de las etiquetas del eje x para mejorar la legibilidad\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Ajustar el espacio entre los gráficos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar los gráficos\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wnEv3zAJDy7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_table = pd.crosstab(index=df_train['ProductCD'], columns=df_train['isFraud'])\n",
        "\n",
        "# Ordenar la tabla por la columna que representa los fraudes (1)\n",
        "count_table = count_table.sort_values(by=1, ascending=False)\n",
        "\n",
        "# Calcular el porcentaje de cada categoría en ProductCD\n",
        "count_table_percent = count_table.apply(lambda x: round(x / x.sum() * 100, 2), axis=1)\n",
        "\n",
        "# Mostrar la tabla de conteo desglosada por ProductCD y isFraud en porcentaje\n",
        "print(count_table_percent)"
      ],
      "metadata": {
        "id": "HghHO8yDD_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeWUv6XWqCDt"
      },
      "source": [
        "**Observación:**\n",
        "- El tipo de producto con mayor transacción es el \"W\" con 74.39%, seguido del producto \"C\" y los demás.\n",
        "-  De la tabla de porcentaje de fraude, cada producto tiene diferentes porcentajes, el producto con mayor porcentaje de fraude es el producto C"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df_train, x='ProductCD', y='TransactionAmt',hue='isFraud')\n",
        "plt.xlabel('ProductCD')\n",
        "plt.ylabel('TransactionAmt')\n",
        "plt.title('Boxplot de TransactionAmt por ProductCD')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6wvV_SZtFNlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar filas con valores NaN en 'TransactionAmt'\n",
        "df_train_clean = df_train.dropna(subset=['TransactionAmt'])\n",
        "\n",
        "# Calcular estadísticas descriptivas\n",
        "stats_prod = df_train_clean.groupby(['ProductCD', 'isFraud'])['TransactionAmt'].describe().round(2)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(stats_prod)"
      ],
      "metadata": {
        "id": "0v9EREelKcWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Observando las medianas, notamos que para 'C' y 'S' son prácticamente iguales. 'H' difiere notablemente con una mediana aproximadamente tres veces mayor, mientras que 'R' muestra una diferencia de casi el doble. Por otro lado, 'W' exhibe una mediana casi el doble en comparación con los otros."
      ],
      "metadata": {
        "id": "dBZhkU7rLDkX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmNweq6TqCDt"
      },
      "source": [
        "### Característica Addr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIceI_aqCDu"
      },
      "source": [
        "**addr**: dirección.\n",
        "- \"Ambas direcciones son para el comprador: addr1 como región de facturación, addr2 como país de facturación.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['addr1'].dtype"
      ],
      "metadata": {
        "id": "dv49bHbV7TQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Suponiendo que df_train tiene las columnas 'addr1' y 'isFraud'\n",
        "\n",
        "# Filtrar y copiar el DataFrame eliminando filas con valores nulos en 'addr1'\n",
        "df_filtered = df_train.dropna(subset=['addr1']).copy()\n",
        "df_filtered['addr1'] = df_filtered['addr1'].astype(int)  # Convertir 'addr1' a tipo entero\n",
        "\n",
        "# Separar por fraude y no fraude\n",
        "df_fraude = df_filtered[df_filtered['isFraud'] == 1]\n",
        "df_no_fraude = df_filtered[df_filtered['isFraud'] == 0]\n",
        "\n",
        "# Calcular el tamaño de cada grupo agrupando por 'addr1' para fraude y no fraude\n",
        "addr_fraude = df_fraude.groupby('addr1').size().reset_index(name='N° Registros_Fraude')\n",
        "addr_no_fraude = df_no_fraude.groupby('addr1').size().reset_index(name='N° Registros_No_Fraude')\n",
        "\n",
        "# Combinar los resultados en un DataFrame final\n",
        "addr_resultado = pd.merge(addr_fraude, addr_no_fraude, on='addr1', how='outer').fillna(0)\n",
        "\n",
        "# Calcular el porcentaje sobre el total de cada fila\n",
        "addr_resultado['Porcentaje_Fraude %'] = round((addr_resultado['N° Registros_Fraude'] / (addr_resultado['N° Registros_Fraude'] +addr_resultado['N° Registros_No_Fraude']  )) * 100, 2)\n",
        "addr_resultado['Porcentaje_No_Fraude %'] = round((addr_resultado['N° Registros_No_Fraude'] / (addr_resultado['N° Registros_Fraude'] +addr_resultado['N° Registros_No_Fraude']  )) * 100, 2)\n",
        "\n",
        "# Ordenar el DataFrame por número de registros de fraude de manera descendente y mostrar los primeros 5 grupos\n",
        "addr_resultado_porcentaje_fraude = addr_resultado.sort_values(by='Porcentaje_Fraude %', ascending=False).head(20)\n",
        "addr_resultado_porcentaje_fraude.head(10)\n"
      ],
      "metadata": {
        "id": "BG9hbI2vbcTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='addr1', y='N° Registros_Fraude', data=addr_resultado_porcentaje_fraude, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='addr1', y='N° Registros_No_Fraude', data=addr_resultado_porcentaje_fraude, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por addr1 ordenado por mayor porcentaje de fraude', fontsize=16)\n",
        "plt.xlabel('addr1', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "sns.despine()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xSUw14ynbjSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "addr_resultado_fraude=addr_resultado.sort_values(by=['N° Registros_Fraude',], ascending=False).head(20)\n",
        "addr_resultado_fraude.head(10)\n"
      ],
      "metadata": {
        "id": "s7MpNvFjg8DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='addr1', y='N° Registros_Fraude', data=addr_resultado_fraude, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='addr1', y='N° Registros_No_Fraude', data=addr_resultado_fraude, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por addr1 ordenado por mayor numero de  fraude', fontsize=16)\n",
        "plt.xlabel('addr1', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "sns.despine()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BQU0OMfOhPTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='addr1', y='Porcentaje_Fraude %', data=addr_resultado, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='addr1', y='Porcentaje_No_Fraude %', data=addr_resultado, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por addr1 ordenado por mayor numero de  fraude', fontsize=16)\n",
        "plt.xlabel('addr1', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "sns.despine()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N14e-jB6jP4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Si ordenamos por porcentaje de fraude, encontramos regiones donde la proporción de operaciones fraudulentas es más alta. Sin embargo, esto puede deberse a que estas regiones tienen un número total de transacciones relativamente bajo. Por otro lado, al ordenar por mayor cantidad de fraude en términos absolutos, observamos que el porcentaje de transacciones fraudulentas en estas regiones de facturación no supera el 2.6%, a pesar de tener un mayor volumen de transacciones en comparación con otras regiones.\n",
        "\n",
        "Por lo tanto, esta columna no aporta mucho a la detección de fraudes, ya que no hay regiones preferenciales específicas para actividades fraudulentas"
      ],
      "metadata": {
        "id": "dsfny5-adsbA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_qQFMpuqCDw"
      },
      "source": [
        "En la tabla de arriba muestra las 10 regiones con mayor transacciones"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addr2"
      ],
      "metadata": {
        "id": "EQB4-hfbmFjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Suponiendo que df_train tiene las columnas 'addr2' y 'isFraud'\n",
        "\n",
        "# Filtrar y copiar el DataFrame eliminando filas con valores nulos en 'addr2'\n",
        "df_filtered = df_train.dropna(subset=['addr2']).copy()\n",
        "df_filtered['addr2'] = df_filtered['addr2'].astype(int)  # Convertir 'addr2' a tipo entero\n",
        "\n",
        "# Separar por fraude y no fraude\n",
        "df_fraude = df_filtered[df_filtered['isFraud'] == 1]\n",
        "df_no_fraude = df_filtered[df_filtered['isFraud'] == 0]\n",
        "\n",
        "# Calcular el tamaño de cada grupo agrupando por 'addr2' para fraude y no fraude\n",
        "addr_fraude = df_fraude.groupby('addr2').size().reset_index(name='N° Registros_Fraude')\n",
        "addr_no_fraude = df_no_fraude.groupby('addr2').size().reset_index(name='N° Registros_No_Fraude')\n",
        "\n",
        "# Combinar los resultados en un DataFrame final\n",
        "addr_resultado = pd.merge(addr_fraude, addr_no_fraude, on='addr2', how='outer').fillna(0)\n",
        "\n",
        "# Calcular el porcentaje sobre el total de cada fila\n",
        "addr_resultado['Porcentaje_Fraude %'] = round((addr_resultado['N° Registros_Fraude'] / (addr_resultado['N° Registros_Fraude'] +addr_resultado['N° Registros_No_Fraude']  )) * 100, 2)\n",
        "addr_resultado['Porcentaje_No_Fraude %'] = round((addr_resultado['N° Registros_No_Fraude'] / (addr_resultado['N° Registros_Fraude'] +addr_resultado['N° Registros_No_Fraude']  )) * 100, 2)\n",
        "\n",
        "# Ordenar el DataFrame por número de registros de fraude de manera descendente y mostrar los primeros 5 grupos\n",
        "addr_resultado_porcentaje_fraude = addr_resultado.sort_values(by='Porcentaje_Fraude %', ascending=False).head(20)\n",
        "addr_resultado_porcentaje_fraude.head(10)\n"
      ],
      "metadata": {
        "id": "msVIBwXFmI19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='addr2', y='N° Registros_Fraude', data=addr_resultado_porcentaje_fraude, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='addr2', y='N° Registros_No_Fraude', data=addr_resultado_porcentaje_fraude, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por addr2 ordenado por mayor porcentaje de fraude', fontsize=16)\n",
        "plt.xlabel('addr2', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "sns.despine()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6VgvNrKMmXnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "addr_resultado_fraude=addr_resultado.sort_values(by=['N° Registros_Fraude',], ascending=False).head(20)\n",
        "addr_resultado_fraude.head(10)"
      ],
      "metadata": {
        "id": "nGoGnzZMmvID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='addr2', y='N° Registros_Fraude', data=addr_resultado_fraude, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='addr2', y='N° Registros_No_Fraude', data=addr_resultado_fraude, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por addr2 ordenado por mayor numero de  fraude', fontsize=16)\n",
        "plt.xlabel('addr2', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "sns.despine()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "__MfU81Fmo09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='addr2', y='Porcentaje_Fraude %', data=addr_resultado, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='addr2', y='Porcentaje_No_Fraude %', data=addr_resultado, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por addr2 ordenado por mayor numero de  fraude', fontsize=16)\n",
        "plt.xlabel('addr2', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "sns.despine()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9FzSc4Dym4EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EvcTTOQqCDx"
      },
      "source": [
        "**Obervación:**\n",
        "- Observando los datos por el código de país de facturación (addr2), notamos que el país con el código 87 tiene el mayor número de fraudes registrados. Sin embargo, el porcentaje de transacciones fraudulentas en este país no supera el 2.4% del total de sus transacciones. Por otro lado, hay países con porcentajes de fraude muy elevados, pero tienen un número reducido de transacciones en comparación.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFG_TLHZqCDy"
      },
      "source": [
        "### Columna P_emaildomain\n",
        "\n",
        "**P_emaildomain**: dominio de correo electrónico del comprador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEwKqLzNqCDy"
      },
      "outputs": [],
      "source": [
        "df_train['P_emaildomain'].value_counts().head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUPO5kfKqCDy"
      },
      "outputs": [],
      "source": [
        "top_5_values = df_train['P_emaildomain'].value_counts().head(5)\n",
        "sns.countplot(data=df_train, x='P_emaildomain', order=top_5_values.index,hue='isFraud')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Top 5 Purchaser_emaildomain')\n",
        "plt.xlabel('P_emaildomain')\n",
        "plt.ylabel('Conteo')\n",
        "plt.tight_layout()\n",
        "#plt.savefig(base_dir+ 'emaildomaintop5')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Suponiendo que df_train tiene las columnas 'P_emaildomain' y 'isFraud'\n",
        "\n",
        "# Filtrar y copiar el DataFrame eliminando filas con valores nulos en 'P_emaildomain'\n",
        "df_filtered = df_train.dropna(subset=['P_emaildomain']).copy()\n",
        "#df_filtered['P_emaildomain'] = df_filtered['P_emaildomain'].astype(int)  # Convertir 'P_emaildomain' a tipo entero\n",
        "\n",
        "# Separar por fraude y no fraude\n",
        "df_fraude = df_filtered[df_filtered['isFraud'] == 1]\n",
        "df_no_fraude = df_filtered[df_filtered['isFraud'] == 0]\n",
        "\n",
        "# Calcular el tamaño de cada grupo agrupando por 'P_emaildomain' para fraude y no fraude\n",
        "addr_fraude = df_fraude.groupby('P_emaildomain').size().reset_index(name='N° Registros_Fraude')\n",
        "addr_no_fraude = df_no_fraude.groupby('P_emaildomain').size().reset_index(name='N° Registros_No_Fraude')\n",
        "\n",
        "# Combinar los resultados en un DataFrame final\n",
        "addr_resultado = pd.merge(addr_fraude, addr_no_fraude, on='P_emaildomain', how='outer').fillna(0)\n",
        "\n",
        "# Calcular el porcentaje sobre el total de cada fila\n",
        "addr_resultado['Porcentaje_Fraude %'] = round((addr_resultado['N° Registros_Fraude'] / (addr_resultado['N° Registros_Fraude'] +addr_resultado['N° Registros_No_Fraude']  )) * 100, 2)\n",
        "addr_resultado['Porcentaje_No_Fraude %'] = round((addr_resultado['N° Registros_No_Fraude'] / (addr_resultado['N° Registros_Fraude'] +addr_resultado['N° Registros_No_Fraude']  )) * 100, 2)\n",
        "\n",
        "# Ordenar el DataFrame por número de registros de fraude de manera descendente y mostrar los primeros 5 grupos\n",
        "addr_resultado_porcentaje_fraude = addr_resultado.sort_values(by='Porcentaje_Fraude %', ascending=False)\n",
        "addr_resultado_porcentaje_fraude.head(10)\n"
      ],
      "metadata": {
        "id": "6PQyI0zwqOHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='P_emaildomain', y='N° Registros_Fraude', data=addr_resultado_porcentaje_fraude, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='P_emaildomain', y='N° Registros_No_Fraude', data=addr_resultado_porcentaje_fraude, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por P_emaildomain ordenado por mayor porcentaje de fraude', fontsize=16)\n",
        "plt.xlabel('P_emaildomain', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rfcS30Qoq_Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j5MPPdbyqvtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "addr_resultado_fraude=addr_resultado.sort_values(by=['N° Registros_Fraude',], ascending=False)\n",
        "addr_resultado_fraude.head(10)"
      ],
      "metadata": {
        "id": "FYix85qtrNhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Mh2ds44KybkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='P_emaildomain', y='Porcentaje_Fraude %', data=addr_resultado, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='P_emaildomain', y='Porcentaje_No_Fraude %', data=addr_resultado, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por P_emaildomain ordenado por mayor numero de  fraude', fontsize=16)\n",
        "plt.xlabel('P_emaildomain', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dm5xkHrosNmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Los dominios de correo electrónico con el mayor número de fraudes son Gmail, seguido de Hotmail y Yahoo. Sin embargo, es importante tener en cuenta que estos representan solo un pequeño porcentaje del total de transacciones. Además, hay dominios donde el porcentaje de fraudes es considerablemente mayor, pero con un número mucho menor de transacciones.\n",
        "-  Dominio de correo electrónico del comprador (purchaser) y del destinatario (recipient) respectivamente la mayor parte de la transacción lo hace con \"gmail\""
      ],
      "metadata": {
        "id": "cOuYmLdJyc2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YFAYws1jy1gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Suponiendo que df_train tiene las columnas 'R_emaildomain' y 'isFraud'\n",
        "\n",
        "# Filtrar y copiar el DataFrame eliminando filas con valores nulos en 'R_emaildomain'\n",
        "df_filtered = df_train.dropna(subset=['R_emaildomain']).copy()\n",
        "#df_filtered['R_emaildomain'] = df_filtered['R_emaildomain'].astype(int)  # Convertir 'R_emaildomain' a tipo entero\n",
        "\n",
        "# Separar por fraude y no fraude\n",
        "df_fraude = df_filtered[df_filtered['isFraud'] == 1]\n",
        "df_no_fraude = df_filtered[df_filtered['isFraud'] == 0]\n",
        "\n",
        "# Calcular el tamaño de cada grupo agrupando por 'R_emaildomain' para fraude y no fraude\n",
        "addr_fraude = df_fraude.groupby('R_emaildomain').size().reset_index(name='N° Registros_Fraude')\n",
        "addr_no_fraude = df_no_fraude.groupby('R_emaildomain').size().reset_index(name='N° Registros_No_Fraude')\n",
        "\n",
        "# Combinar los resultados en un DataFrame final\n",
        "addr_resultado = pd.merge(addr_fraude, addr_no_fraude, on='R_emaildomain', how='outer').fillna(0)\n",
        "\n",
        "# Calcular el porcentaje sobre el total de cada fila\n",
        "addr_resultado['Porcentaje_Fraude %'] = round((addr_resultado['N° Registros_Fraude'] / (addr_resultado['N° Registros_Fraude'] +addr_resultado['N° Registros_No_Fraude']  )) * 100, 2)\n",
        "addr_resultado['Porcentaje_No_Fraude %'] = round((addr_resultado['N° Registros_No_Fraude'] / (addr_resultado['N° Registros_Fraude'] +addr_resultado['N° Registros_No_Fraude']  )) * 100, 2)\n",
        "\n",
        "# Ordenar el DataFrame por número de registros de fraude de manera descendente y mostrar los primeros 5 grupos\n",
        "addr_resultado_porcentaje_fraude = addr_resultado.sort_values(by='Porcentaje_Fraude %', ascending=False)\n",
        "addr_resultado_porcentaje_fraude.head(10)\n"
      ],
      "metadata": {
        "id": "TpVLgAgJy0-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "addr_resultado_fraude=addr_resultado.sort_values(by=['N° Registros_Fraude',], ascending=False)\n",
        "addr_resultado_fraude.head(10)"
      ],
      "metadata": {
        "id": "vV4h0qOHzLSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x='R_emaildomain', y='N° Registros_Fraude', data=addr_resultado_porcentaje_fraude, color='orange', alpha=0.8, label='Fraude')\n",
        "sns.barplot(x='R_emaildomain', y='N° Registros_No_Fraude', data=addr_resultado_porcentaje_fraude, color='blue', alpha=0.4, label= 'No Fraude')\n",
        "plt.title('Top  Números de Registros por R_emaildomain ordenado por mayor porcentaje de fraude', fontsize=16)\n",
        "plt.xlabel('R_emaildomain', fontsize=14)\n",
        "plt.ylabel('Número de Registros', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qasMdOwkzRNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Los dominios de correo electrónico con el mayor número de fraudes son Gmail, seguido de Hotmail y Yahoo. Sin embargo, es importante tener en cuenta que estos representan solo un pequeño porcentaje del total de transacciones. Además, hay dominios donde el porcentaje de fraudes es considerablemente mayor, pero con un número mucho menor de transacciones."
      ],
      "metadata": {
        "id": "erQN4-eSznvV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAJ_AbwJqCDz"
      },
      "source": [
        "## Car"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPXnPkN6qCD0"
      },
      "source": [
        "\n",
        "**card1 - card6**: información de la tarjeta de pago, como tipo de tarjeta, categoría de tarjeta, banco emisor, país, etc.\n",
        "- \"Información de la tarjeta de pago, como tipo de tarjeta, categoría de tarjeta, banco emisor, país, etc.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cards = ['card1', 'card2', 'card3', 'card4', 'card5', 'card6']\n",
        "\n",
        "# Crear subplots para cada variable de tarjeta\n",
        "fig, axs = plt.subplots(3, 2, figsize=(15, 15), sharey=False, tight_layout=True)\n",
        "\n",
        "# Iterar sobre las variables de tarjeta y los subplots correspondientes\n",
        "for i, card in enumerate(cards):\n",
        "    # Histograma de densidad para datos no fraudulentos\n",
        "    sns.histplot(data=df_train[df_train['isFraud'] == 0], x=card, bins=30,\n",
        "                 edgecolor=\"white\", linewidth=0.7, log_scale=False, ax=axs[i//2, i%2], color='tab:blue', label='No Fraude', kde=True, stat='density')\n",
        "\n",
        "    # Histograma de densidad para datos fraudulentos\n",
        "    sns.histplot(data=df_train[df_train['isFraud'] == 1], x=card, bins=30,\n",
        "                 edgecolor=\"white\", linewidth=0.7, log_scale=False, ax=axs[i//2, i%2], color='tab:orange', label='Fraude', kde=True, stat='density')\n",
        "\n",
        "    # Configuraciones adicionales para cada subplot\n",
        "    axs[i//2, i%2].set_xlabel(card)\n",
        "    axs[i//2, i%2].legend()\n",
        "\n",
        "# Ajustar el espacio entre subplots y mostrar la figura\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JOYeulBcMSk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_card = df_train.groupby('isFraud')[cards].describe().T.round(2)\n",
        "stat_card"
      ],
      "metadata": {
        "id": "vGCLBJLINoh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Las variables Card1 y Card2 son valores numéricos. En la gráfica de distribución, se observa que sus distribuciones normalizadas no muestran grandes diferencias entre los casos con fraude y sin fraude. Además, los valores estadísticos, como la media y la dispersión, son muy similares para ambos grupos.\n",
        "- Lo mismo ocurre con las variables categóricas Card3 y Card5, donde los valores más frecuentes coinciden. Sin embargo, en Card5, se observa que hay ciertos valores para los cuales la frecuencia es más alta en los casos de fraude en comparación con los no fraudulentos, lo que indica una diferencia en la distribución entre ambos grupos.\n",
        "- En Card4, las empresas emisoras de tarjetas muestran la misma distribución tanto en casos de fraude como en casos no fraudulentos.\n",
        "- Sin embargo, en Card6, que representa el tipo de pago (tarjeta o débito), se observan diferencias significativas en las distribuciones entre ambos grupos"
      ],
      "metadata": {
        "id": "cMrEM_zLO4L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df_train, x='card6', y='TransactionAmt',hue='isFraud')\n",
        "plt.xlabel('card6')\n",
        "plt.ylabel('TransactionAmt')\n",
        "plt.title('Boxplot de TransactionAmt por card6')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CwOm-mQvRqx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar filas con valores NaN en 'TransactionAmt'\n",
        "df_train_clean = df_train.dropna(subset=['TransactionAmt'])\n",
        "\n",
        "# Calcular estadísticas descriptivas\n",
        "stats_prod = df_train_clean.groupby(['card6', 'isFraud'])['TransactionAmt'].describe().round(2)\n",
        "\n",
        "# Mostrar el resultado\n",
        "stats_prod"
      ],
      "metadata": {
        "id": "vp8Lf_bZSkzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- En la categoría de crédito, se observa una diferencia del 10% en la mediana, mientras que los otros cuartiles son prácticamente similares.\n",
        "- Por otro lado, en la categoría de débito, la diferencia en la mediana es del 5%; el cuartil Q2 casi coincide, pero no así el cuartil Q3."
      ],
      "metadata": {
        "id": "fRjhNqUVTCb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df_train, x='card4', y='TransactionAmt',hue='isFraud')\n",
        "plt.xlabel('card4')\n",
        "plt.ylabel('TransactionAmt')\n",
        "plt.title('Boxplot de TransactionAmt por card4')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BPyIRXZzSJXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar filas con valores NaN en 'TransactionAmt'\n",
        "df_train_clean = df_train.dropna(subset=['TransactionAmt'])\n",
        "\n",
        "# Calcular estadísticas descriptivas\n",
        "stats_prod = df_train_clean.groupby(['card4', 'isFraud'])['TransactionAmt'].describe().round(2)\n",
        "\n",
        "# Mostrar el resultado\n",
        "\n",
        "stats_prod"
      ],
      "metadata": {
        "id": "NjGZGg7rS5Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Se observa una notable diferencia en las distribuciones entre las distintas empresas de tarjeta de crédito. Discover muestra la mayor disparidad entre fraude y no fraude; se pueden apreciar estas diferencias en los valores de sus cuartiles. Le sigue American Express en términos de divergencia entre las distribuciones de fraude y no fraude."
      ],
      "metadata": {
        "id": "IO---1_xUD86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## M1-M9"
      ],
      "metadata": {
        "id": "w1w5yXqJVsN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']"
      ],
      "metadata": {
        "id": "J0EA4v7vUV1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "M = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
        "\n",
        "# Crear subplots para cada variable de tarjeta\n",
        "fig, axs = plt.subplots(3, 3, figsize=(15, 15), sharey=False, tight_layout=True)\n",
        "\n",
        "# Iterar sobre las variables de tarjeta y los subplots correspondientes\n",
        "for i, m in enumerate(M):\n",
        "    # Histograma de densidad para datos no fraudulentos\n",
        "    sns.histplot(data=df_train[df_train['isFraud'] == 0], x=m, bins=30,\n",
        "                 edgecolor=\"white\", linewidth=0.7, log_scale=False, ax=axs[i//3, i%3], color='tab:blue', label='No Fraude', stat='density')\n",
        "\n",
        "    # Histograma de densidad para datos fraudulentos\n",
        "    sns.histplot(data=df_train[df_train['isFraud'] == 1], x=m, bins=30,\n",
        "                 edgecolor=\"white\", linewidth=0.7, log_scale=False, ax=axs[i//3, i%3], color='tab:orange', label='Fraude', stat='density',alpha=0.3)\n",
        "\n",
        "    # Configuraciones adicionales para cada subplot\n",
        "    axs[i//3, i%3].set_xlabel(m)\n",
        "    axs[i//3, i%3].set_ylabel('Densidad')\n",
        "    axs[i//3, i%3].legend()\n",
        "\n",
        "# Ajustar el espacio entre subplots y mostrar la figura\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EFkoJ2f0WNfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_percent = (df_train.groupby('isFraud')[M].count()).round(2)\n",
        "stats_percent"
      ],
      "metadata": {
        "id": "PCocoqHkZBDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una figura y subplots\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(18, 12))\n",
        "\n",
        "# Ajustar espacio entre subplots\n",
        "plt.tight_layout(pad=4.0)\n",
        "\n",
        "# Iterar sobre las columnas y los ejes para crear los boxplots\n",
        "for ax, col in zip(axes.flat, M):\n",
        "    sns.boxplot(data=df_train, x=col, y='TransactionAmt', hue='isFraud', ax=ax)\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel('TransactionAmt')\n",
        "    ax.set_title(f'Boxplot de TransactionAmt por {col}')\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i9m4v6faQ6gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calcular_estadisticas_con_diferencias_relativas(df, columnas, group_by_cols):\n",
        "    \"\"\"\n",
        "    Calcula estadísticas descriptivas para las columnas especificadas en un DataFrame, agrupadas por las columnas especificadas,\n",
        "    y añade una fila con las diferencias relativas en porcentaje entre fraude y no fraude.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): DataFrame que contiene los datos.\n",
        "    columnas (list): Lista de columnas para las cuales se calcularán las estadísticas.\n",
        "    group_by_cols (list): Lista de columnas por las cuales se agruparán los datos.\n",
        "\n",
        "    Returns:\n",
        "    dict: Un diccionario donde las claves son los nombres de las columnas y los valores son DataFrames con las estadísticas descriptivas.\n",
        "    \"\"\"\n",
        "    estadisticas = {}\n",
        "    for col in columnas:\n",
        "        # Crear una copia temporal del DataFrame y eliminar valores nulos\n",
        "        temp_df = df.dropna(subset=group_by_cols + [col])\n",
        "        stats = temp_df.groupby(group_by_cols + [col])['TransactionAmt'].describe().round(2)\n",
        "\n",
        "        # Calcular diferencias relativas entre fraude y no fraude\n",
        "        if 'isFraud' in group_by_cols:\n",
        "            fraude = stats.xs(1, level='isFraud')\n",
        "            no_fraude = stats.xs(0, level='isFraud')\n",
        "            diferencias_relativas = ((fraude - no_fraude) / no_fraude * 100).rename(index=lambda x: f'Diff_%{x}').round(1)\n",
        "            stats = pd.concat([stats, diferencias_relativas])\n",
        "\n",
        "        estadisticas[col] = stats\n",
        "    return estadisticas\n",
        "\n",
        "# Lista de columnas M\n",
        "M = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
        "\n",
        "# Calcular estadísticas descriptivas para cada columna en M agrupadas por la columna correspondiente y 'isFraud'\n",
        "for col in M:\n",
        "    stats = calcular_estadisticas_con_diferencias_relativas(df_train_clean, [col], ['isFraud'])\n",
        "    print(f\"Estadísticas para {col}:\\n\")\n",
        "    print(stats[col])\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "6s8g_zkeRhTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- se observa una notable diferencia entre las transacciones fraudulentas y no fraudulentas en todas las categorías de M. Las medidas de medias, medianas y cuartiles muestran variaciones significativas, lo cual la convierte en una excelente opción para el entrenamiento."
      ],
      "metadata": {
        "id": "kzzGcVu6V-q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "ZISXT5nXNVBs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9lRwFv5qCD1"
      },
      "source": [
        "### **C1-C14**\n",
        "\n",
        "**C1-C14**: conteo, como cuántas direcciones están asociadas con la tarjeta de pago, etc.\n",
        "- \"Conteos de variables C1-C15: ¿Serían como recuentos de números de teléfono, direcciones de correo electrónico, nombres asociados con el usuario? Tu suposición es buena, además de dispositivos, direcciones IP, dirección de facturación, etc. También son para el comprador y el destinatario, lo que duplica el número.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2wIS3T1qCD1"
      },
      "outputs": [],
      "source": [
        "c_valores = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10',\n",
        "       'C11', 'C12', 'C13', 'C14']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cc_sVv-qqCD1"
      },
      "outputs": [],
      "source": [
        "df_train[c_valores].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbUdazM_qCD2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Crear subplots para cada rango de valor\n",
        "fig, axs = plt.subplots(7, 2, figsize=(20, 15), sharey=False, tight_layout=True)\n",
        "\n",
        "# Iterar sobre los subplots y los rangos\n",
        "for i, ax in enumerate(axs.flatten()):\n",
        "        sns.histplot(data=df_train, x=c_valores[i], bins=30,\n",
        "                     edgecolor=\"white\", linewidth=0.7, log_scale=True, ax=ax,hue='isFraud')\n",
        "\n",
        "# Ajustar el espacio entre subplots y mostrar la figura\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3v7mnoqqCD3"
      },
      "source": [
        "### Análisis Bivariado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42CoTreFqCD3"
      },
      "source": [
        "### Características Numeŕicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ5We0veqCD3"
      },
      "outputs": [],
      "source": [
        "df_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLB2RJYMqCD4"
      },
      "outputs": [],
      "source": [
        "# palette = 'Set2'  # Puedes cambiar 'Set2' por otras paletas como 'Set1', 'Set3', 'Dark2', etc.\n",
        "\n",
        "# # Generar los boxplots con la paleta de colores genérica\n",
        "# for column in df_train.select_dtypes(include=['number']).columns:\n",
        "#     if column != 'isFraud':\n",
        "#         plt.figure(figsize=(10, 6))\n",
        "#         sns.boxplot(x='isFraud', y=column, data=df_train, hue='isFraud', palette=palette, legend=False)\n",
        "#         plt.title(f'Relación entre {column} y target')\n",
        "#         plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK7HkXfFqCD4"
      },
      "source": [
        "\n",
        "**Observaciones:**\n",
        "Las características numéricas se analizaron en relación con la variable objetivo \"isFraud\". Se observó lo siguiente:\n",
        "\n",
        "- TransactionDT: Tanto las transacciones fraudulentas como las no fraudulentas presentan distribuciones similares.\n",
        "- TransactionAmt: Se observa una mayor diferencia debido a la presencia de valores atípicos y diferentes distribuciones entre los casos con fraude y sin fraude.\n",
        "- Addr1:Las direcciones por región son similares tanto para los casos con fraude como para los casos sin fraude.\n",
        "- Add2: Las direcciones por país son similares tanto para los casos con fraude como para los casos sin fraude.\n",
        "- Card1: Las distribución con fraude y no fraude son similares\n",
        "- Card2 y Card5: Hay diferencia entre ellas significativas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tun4UpWqCD4"
      },
      "outputs": [],
      "source": [
        "df_stat = df_train.groupby('isFraud').describe(include='number').T.round(2)\n",
        "df_stat['diferencia_absoluta'] = df_stat['No'] - df_stat['Sí']\n",
        "df_stat['diferencia_relativa %'] = round(abs((df_stat['diferencia_absoluta'] / df_stat.sum(axis=1)) * 100),2)\n",
        "\n",
        "df_stat.sort_values(by='diferencia_relativa %',ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N34Vt3dQqCD5"
      },
      "outputs": [],
      "source": [
        "df_stat.loc[df_stat.index.get_level_values(1) == 'mean'].sort_values(by='diferencia_relativa %',ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Z5TYftqCD5"
      },
      "source": [
        "** Observación**\n",
        "- Se observa que las diferencias relativas en los valores medios de las características numéricas son menores al 1%, excepto en \"TransactionAmt\" que es el del 21.69%, lo cual podría deberse a la presencia de valores atípicos y card2 que es del 2.88%,\n",
        "Esto podŕia indicar una dificultad en el entrenamiento con las características numéricas, ya que sus distribuciones no son muy difrentes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahV_YDJlqCD5"
      },
      "source": [
        "### Características Categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPG3Ps9EqCD6"
      },
      "outputs": [],
      "source": [
        "count_table = pd.crosstab(index=df_train['ProductCD'], columns=df_train['isFraud'])\n",
        "count_table = count_table.sort_values(by='Sí',ascending=False)\n",
        "# Configurar el estilo y tamaño del gráfico\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Crear el countplot utilizando seaborn\n",
        "sns.countplot(data=df_train, x='ProductCD', hue='isFraud', palette='Set2')\n",
        "\n",
        "# Ajustar el formato de las etiquetas del eje x para mejorar la legibilidad\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# Añadir título y etiquetas de los ejes\n",
        "plt.title('Countplot de ProductCD desglosado por isFraud')\n",
        "plt.xlabel('ProductCD')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Mostrar el gráfico con leyenda\n",
        "plt.legend(title='isFraud')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mostrar la tabla de conteo desglosada por ProductCD y isFraud\n",
        "print(count_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qahiET9MqCD6"
      },
      "outputs": [],
      "source": [
        "\n",
        "top_5_domains = df_train['P_emaildomain'].value_counts().head(5).index\n",
        "df_top_5 = df_train[df_train['P_emaildomain'].isin(top_5_domains)]\n",
        "sns.countplot(data=df_top_5, x='P_emaildomain', hue='isFraud')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Countplot de los 5 primeros P_emaildomain separado por isFraud')\n",
        "plt.xlabel('P_emaildomain')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='isFraud')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1rgcA7VqCD6"
      },
      "outputs": [],
      "source": [
        "count_table = pd.crosstab(index=df_train['P_emaildomain'], columns=df_train['isFraud'])\n",
        "count_table = count_table.sort_values(by='Sí',ascending=False).head(5)\n",
        "count_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRa5gz5pqCD7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Crear tabla de contingencia (crosstab) desglosando por P_emaildomain y isFraud\n",
        "count_table = pd.crosstab(index=df_train['P_emaildomain'], columns=df_train['isFraud'])\n",
        "\n",
        "# Ordenar la tabla por la cantidad de fraudes (isFraud == 1)\n",
        "count_table = count_table.sort_values(by=1, ascending=False).head(5)\n",
        "\n",
        "# Calcular el porcentaje en función del total de cada columna\n",
        "count_table_percentage = count_table.apply(lambda x: x / x.sum() * 100, axis=0).round(2)\n",
        "\n",
        "# Mostrar la tabla de contingencia y su porcentaje\n",
        "print(\"Tabla de Contingencia :\")\n",
        "print(count_table)\n",
        "print(\"\\nPorcentaje en función del total de cada columna:\")\n",
        "print(count_table_percentage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n05uKdHqCD7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Crear tabla de contingencia (crosstab) desglosando por ProductCD y isFraud\n",
        "count_table = pd.crosstab(index=df_train['ProductCD'], columns=df_train['isFraud'])\n",
        "\n",
        "# Ordenar la tabla por la cantidad de fraudes (isFraud == 1)\n",
        "count_table = count_table.sort_values(by='Sí', ascending=False)\n",
        "\n",
        "# Calcular el porcentaje en función del total de cada columna\n",
        "count_table_percentage = count_table.apply(lambda x: x / x.sum() * 100, axis=0).round(2)\n",
        "\n",
        "# Mostrar la tabla de contingencia y su porcentaje\n",
        "print(\"Tabla de Contingencia :\")\n",
        "print(count_table)\n",
        "print(\"\\nPorcentaje en función del total de cada columna:\")\n",
        "print(count_table_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RKHFTUGqCD8"
      },
      "source": [
        "### Cards Categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb4gJMSXqCD8"
      },
      "outputs": [],
      "source": [
        "df_train[cards].select_dtypes('object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkP_L6_UqCD8"
      },
      "outputs": [],
      "source": [
        "\n",
        "sns.countplot(data=df_train, x='card6', hue='isFraud')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Countplot de Card6 Categoría de la tarjeta' )\n",
        "plt.xlabel('Card6 ')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='isFraud')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHXsvNtMqCD9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "sns.countplot(data=df_train, x='card4', hue='isFraud')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Countplot de Card4 Empresa emisora tarjeta' )\n",
        "plt.xlabel('Card4 ')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='isFraud')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eltT7WmqCD9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "sns.countplot(data=df_train, x='card4', hue='card6')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Countplot de Card4 Empresa emisora tarjeta' )\n",
        "plt.xlabel('Card4 ')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Categoría tarjeta')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHGWNVFQqCD-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Crear tabla de contingencia (crosstab) desglosando por ProductCD y isFraud\n",
        "count_table = pd.crosstab(index=df_train['card4'], columns=df_train['isFraud'])\n",
        "\n",
        "# Ordenar la tabla por la cantidad de fraudes (isFraud == 1)\n",
        "count_table = count_table.sort_values(by='Sí', ascending=False)\n",
        "\n",
        "# Calcular el porcentaje en función del total de cada columna\n",
        "count_table_percentage = count_table.apply(lambda x: x / x.sum() * 100, axis=0).round(2)\n",
        "\n",
        "# Mostrar la tabla de contingencia y su porcentaje\n",
        "print(\"Tabla de Contingencia :\")\n",
        "print(count_table)\n",
        "print(\"\\nPorcentaje en función del total de cada columna:\")\n",
        "print(count_table_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENne0cAsqCD-"
      },
      "source": [
        "- La mayoría de los fraude es con 67% con la empresa Visa, seguida por la mastecard con un 29%, seguidas las otras empresas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz8RJzw9qCD-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Crear tabla de contingencia (crosstab) desglosando por ProductCD y isFraud\n",
        "count_table = pd.crosstab(index=df_train['card6'], columns=df_train['isFraud'])\n",
        "\n",
        "# Ordenar la tabla por la cantidad de fraudes (isFraud == 1)\n",
        "count_table = count_table.sort_values(by='Sí', ascending=False)\n",
        "\n",
        "# Calcular el porcentaje en función del total de cada columna\n",
        "count_table_percentage = count_table.apply(lambda x: x / x.sum() * 100, axis=0).round(2)\n",
        "\n",
        "# Mostrar la tabla de contingencia y su porcentaje\n",
        "print(\"Tabla de Contingencia :\")\n",
        "print(count_table)\n",
        "print(\"\\nPorcentaje en función del total de cada columna:\")\n",
        "print(count_table_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST5MoL6aqCD_"
      },
      "source": [
        "- Los valores de fraude con debito es de 57.6% y con credito de 42%, la diferencia es de un 15%, podría ser significativo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPeW4-3pqCD_"
      },
      "source": [
        "**Observación**\n",
        "- ProductCD: El producto con el mayor porcentaje de fraude es \"W\", representando el 66.8 % del total de productos con fraude. Le sigue el producto \"H\" con un 15.19 %, luego \"R\" con un 14.7 %, y en menor medida el producto \"C\" con solo un 3.31 %.\n",
        "- El correo con mayor incidencia de fraude es el de Gmail, alcanzando un 57.96 % del total. Le sigue Yahoo con un 25.33 %, mientras que los demás proveedores de correo tienen una incidencia menor. Es probable que el alto porcentaje de fraudes en cuentas de Gmail se deba a su amplia base de usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tjb8b-zqCD_"
      },
      "source": [
        "### Correlción entre las variables numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQGVBm-HqCD_"
      },
      "outputs": [],
      "source": [
        "df_train['isFraud'] = df_train['isFraud'].replace({'No': 0, 'Sí': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFgvwNimqCEA"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = df_train.select_dtypes(exclude=['object']).corr()\n",
        "\n",
        "# Filtrar para obtener solo las correlaciones con la columna 'isfraud'\n",
        "isfraud_correlation = correlation_matrix[['isFraud']].sort_values(by='isFraud', ascending=False)\n",
        "\n",
        "# Visualización de las correlaciones con 'isfraud'\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(isfraud_correlation, annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
        "plt.title('Correlaciones con isFraud')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW-8IDQRqCEA"
      },
      "source": [
        "**Observación**\n",
        "- Se pude gráfica de correlación entre las variables numéricas se conclute que en general las variables no estan correlacionadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGe5FmmYqCEB"
      },
      "source": [
        "Generamos un archivo csv con Dataframe de los datos de entrenamiento, el que se usara para la segunda parte del proyecto, \"Limpieza y preprocesamiento de los datos\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDtuubZ5qCEB"
      },
      "outputs": [],
      "source": [
        "dir_data_interim = '../data/interim/'\n",
        "ruta_archivo_completa = os.path.join(dir_data_interim, 'train')\n",
        "\n",
        "df_train.to_csv(ruta_archivo_completa, index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEXBXZwzqCEB"
      },
      "source": [
        "### Conclusiones\n",
        "\n",
        "Durante el análisis exploratorio de datos, se realizaron varias observaciones significativas sobre el dataset:\n",
        "\n",
        "- El dataset original contiene más de medio millón de registros, por lo que se aplicó un método de muestreo estratificado para obtener una muestra representativa y manejable.\n",
        "- Se seleccionaron las características más relevantes para el objetivo de detección de fraude en este primer análisis.\n",
        "- Se identificaron columnas con valores nulos, se evaluó su cantidad y porcentaje, así como la correlación entre ellas. Se decidió eliminar aquellas columnas con un alto porcentaje de valores nulos para simplificar el análisis.\n",
        "- Se encontraron y eliminaron valores duplicados, que eran escasos en comparación con el tamaño total del dataset.\n",
        "- Del análisis univariado:\n",
        "  - La columna objetivo \"isFraud\" muestra un desbalance con un 97.6% de registros no fraudulentos, lo cual debe considerarse al entrenar cualquier modelo.\n",
        "  - La columna \"TransactionAmt\", que representa los montos de transacción, presenta distribuciones distintas según los rangos de valores y algunos valores atípicos, sugiriendo la segmentación para el entrenamiento del modelo.\n",
        "  - La columna \"TransactionDT\" muestra una distribución uniforme en los datos.\n",
        "  - La columna \"ProductCD\", que indica el producto de la transacción, muestra que casi el 82.71% de las transacciones corresponden al producto \"W\", seguido por \"R\" con 8.75%, \"H\" con 7.76%, y \"C\" con 0.78%.\n",
        "  - La columna \"addr1\", que representa la dirección por región de los compradores, muestra que el 9.48% de las transacciones provienen de la región \"299\", seguida por \"204\", \"325\", \"264\" y otras regiones con menor porcentaje.\n",
        "  - La columna \"addr2\", que representa la dirección por país, indica que el país con más transacciones tiene el código \"84\", representando el 99% del total de transacciones en el dataset.\n",
        "  - La columna \"P_emaildomain\", que representa los proveedores de correo electrónico de los compradores, muestra que Gmail tiene la mayor incidencia de fraude con un 57.96% del total, seguido por Yahoo con un 25.33%. Otros proveedores tienen una incidencia menor de fraude.\n",
        "\n",
        "- Del análisis bivariado:\n",
        "  - TransactionDT: Tanto las transacciones fraudulentas como las no fraudulentas presentan distribuciones similares.\n",
        "  - TransactionAmt: Se observa una mayor diferencia debido a la presencia de valores atípicos y diferentes distribuciones entre los casos con fraude y sin fraude.\n",
        "  - Addr1:Las direcciones por región son similares tanto para los casos con fraude como para los casos sin fraude.\n",
        "  - Add2: Las direcciones por país son similares tanto para los casos con fraude como para los casos sin fraude.\n",
        "  - Se observa que las diferencias relativas entre si es fraude o no en los valores medios de las características numéricas son menores al 1%, excepto en \"TransactionAmt\", lo cual podría deberse a la presencia de valores atípicos.\n",
        "Esto podŕia indicar una dificultad en el entrenamiento con las características numéricas, ya que sus distribuciones no son muy difrentes\n",
        "  - ProductCD: El producto con el mayor porcentaje de fraude es \"W\", representando el 66.8 % del total de productos con fraude. Le sigue el producto \"H\" con un 15.19 %, luego \"R\" con un 14.7 %, y en menor medida el producto \"C\" con solo un 3.31 %.\n",
        "  - El correo con mayor incidencia de fraude es el de Gmail, alcanzando un 57.96 % del total. Le sigue Yahoo con un 25.33 %, mientras que los demás proveedores de correo tienen una incidencia menor. Es probable que el alto porcentaje de fraudes en cuentas de Gmail se deba a su amplia base de usuario.\n",
        "\n",
        "  \n",
        "\n",
        "Estas conclusiones proporcionan una base sólida para entender la distribución de los datos y guiarán el preprocesamiento adicional y la construcción de modelos en futuros análisis.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}