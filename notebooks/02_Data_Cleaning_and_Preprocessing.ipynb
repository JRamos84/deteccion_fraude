{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Data Cleaning and Preprocessing\n",
    "**Objetivo**: Limpiar y preprocesar los datos para que estén listos para el modelado.\n",
    "**Contenido**:\n",
    "- Manejo de valores nulos.\n",
    "- Creación de nuevas características (feature engineering).\n",
    "- Conversión de tipos de datos.\n",
    "- Codificación de variables categóricas.\n",
    "- Normalización y estandarización de las variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Librerías \n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cargamos los Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trabajaremos exclusivamente con el dataset de entrenamiento \"train_transaction\" para obtener tanto los datos de entrenamiento como los de validación. De este dataset solo tomaremos el 10 % del total de los registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_col_transaction = 'TransactionID,isFraud,TransactionDT,TransactionAmt,ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,dist1,dist2,P_emaildomain,R_emaildomain,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,D1,D2,D3,D4,D5,D6,D7,D8,D9,D10,D11,D12,D13,D14,D15,M1,M2,M3,M4,M5,M6,M7,M8,M9'.split(',')\n",
    "select_col_identity = 'TransactionID,id_01,id_02,id_03,id_04,id_05,id_06,id_07,id_08,id_09,id_10,id_11,id_12,id_13,id_14,id_15,id_16,id_17,id_18,id_19,id_20,id_21,id_22,id_23,id_24,id_25,id_26,id_27,id_28,id_29,id_30,id_31,id_32,id_33,id_34,id_35,id_36,id_37,id_38,DeviceType,DeviceInfo'.split(',')\n",
    "data_dir = '../data/raw/ieee-fraud-detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de porción del Dataset de entrenamiento con Muestreo Estratificado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Data columns (total 95 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   TransactionID   590540 non-null  int64  \n",
      " 1   isFraud         590540 non-null  int64  \n",
      " 2   TransactionDT   590540 non-null  int64  \n",
      " 3   TransactionAmt  590540 non-null  float64\n",
      " 4   ProductCD       590540 non-null  object \n",
      " 5   card1           590540 non-null  int64  \n",
      " 6   card2           581607 non-null  float64\n",
      " 7   card3           588975 non-null  float64\n",
      " 8   card4           588963 non-null  object \n",
      " 9   card5           586281 non-null  float64\n",
      " 10  card6           588969 non-null  object \n",
      " 11  addr1           524834 non-null  float64\n",
      " 12  addr2           524834 non-null  float64\n",
      " 13  dist1           238269 non-null  float64\n",
      " 14  dist2           37627 non-null   float64\n",
      " 15  P_emaildomain   496084 non-null  object \n",
      " 16  R_emaildomain   137291 non-null  object \n",
      " 17  C1              590540 non-null  float64\n",
      " 18  C2              590540 non-null  float64\n",
      " 19  C3              590540 non-null  float64\n",
      " 20  C4              590540 non-null  float64\n",
      " 21  C5              590540 non-null  float64\n",
      " 22  C6              590540 non-null  float64\n",
      " 23  C7              590540 non-null  float64\n",
      " 24  C8              590540 non-null  float64\n",
      " 25  C9              590540 non-null  float64\n",
      " 26  C10             590540 non-null  float64\n",
      " 27  C11             590540 non-null  float64\n",
      " 28  C12             590540 non-null  float64\n",
      " 29  C13             590540 non-null  float64\n",
      " 30  C14             590540 non-null  float64\n",
      " 31  D1              589271 non-null  float64\n",
      " 32  D2              309743 non-null  float64\n",
      " 33  D3              327662 non-null  float64\n",
      " 34  D4              421618 non-null  float64\n",
      " 35  D5              280699 non-null  float64\n",
      " 36  D6              73187 non-null   float64\n",
      " 37  D7              38917 non-null   float64\n",
      " 38  D8              74926 non-null   float64\n",
      " 39  D9              74926 non-null   float64\n",
      " 40  D10             514518 non-null  float64\n",
      " 41  D11             311253 non-null  float64\n",
      " 42  D12             64717 non-null   float64\n",
      " 43  D13             61952 non-null   float64\n",
      " 44  D14             62187 non-null   float64\n",
      " 45  D15             501427 non-null  float64\n",
      " 46  M1              319440 non-null  object \n",
      " 47  M2              319440 non-null  object \n",
      " 48  M3              319440 non-null  object \n",
      " 49  M4              309096 non-null  object \n",
      " 50  M5              240058 non-null  object \n",
      " 51  M6              421180 non-null  object \n",
      " 52  M7              244275 non-null  object \n",
      " 53  M8              244288 non-null  object \n",
      " 54  M9              244288 non-null  object \n",
      " 55  id_01           144233 non-null  float64\n",
      " 56  id_02           140872 non-null  float64\n",
      " 57  id_03           66324 non-null   float64\n",
      " 58  id_04           66324 non-null   float64\n",
      " 59  id_05           136865 non-null  float64\n",
      " 60  id_06           136865 non-null  float64\n",
      " 61  id_07           5155 non-null    float64\n",
      " 62  id_08           5155 non-null    float64\n",
      " 63  id_09           74926 non-null   float64\n",
      " 64  id_10           74926 non-null   float64\n",
      " 65  id_11           140978 non-null  float64\n",
      " 66  id_12           144233 non-null  object \n",
      " 67  id_13           127320 non-null  float64\n",
      " 68  id_14           80044 non-null   float64\n",
      " 69  id_15           140985 non-null  object \n",
      " 70  id_16           129340 non-null  object \n",
      " 71  id_17           139369 non-null  float64\n",
      " 72  id_18           45113 non-null   float64\n",
      " 73  id_19           139318 non-null  float64\n",
      " 74  id_20           139261 non-null  float64\n",
      " 75  id_21           5159 non-null    float64\n",
      " 76  id_22           5169 non-null    float64\n",
      " 77  id_23           5169 non-null    object \n",
      " 78  id_24           4747 non-null    float64\n",
      " 79  id_25           5132 non-null    float64\n",
      " 80  id_26           5163 non-null    float64\n",
      " 81  id_27           5169 non-null    object \n",
      " 82  id_28           140978 non-null  object \n",
      " 83  id_29           140978 non-null  object \n",
      " 84  id_30           77565 non-null   object \n",
      " 85  id_31           140282 non-null  object \n",
      " 86  id_32           77586 non-null   float64\n",
      " 87  id_33           73289 non-null   object \n",
      " 88  id_34           77805 non-null   object \n",
      " 89  id_35           140985 non-null  object \n",
      " 90  id_36           140985 non-null  object \n",
      " 91  id_37           140985 non-null  object \n",
      " 92  id_38           140985 non-null  object \n",
      " 93  DeviceType      140810 non-null  object \n",
      " 94  DeviceInfo      118666 non-null  object \n",
      "dtypes: float64(60), int64(4), object(31)\n",
      "memory usage: 428.0+ MB\n"
     ]
    }
   ],
   "source": [
    "## dataset de entrenamiento\n",
    "seed = 42\n",
    "# Cargar los datos\n",
    "df_transaction_train = pd.read_csv(data_dir + '/train_transaction.csv', usecols=select_col_transaction)\n",
    "df_identity_train = pd.read_csv(data_dir + '/train_identity.csv', usecols=select_col_identity)\n",
    "\n",
    "# Combinar los datasets\n",
    "dataset = pd.merge(df_transaction_train, df_identity_train, on='TransactionID', how='left')\n",
    "\n",
    "# Realizar el muestreo estratificado\n",
    "#data, _ = train_test_split(dataset, stratify=dataset['isFraud'], test_size=0.8, random_state=seed)\n",
    "data = dataset\n",
    "# Mostrar la información del dataset resultante\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armamos un nuevo dataset con las columnas más relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['isFraud', 'TransactionDT', 'TransactionAmt',\n",
    "       'ProductCD','addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain',\n",
    "       'DeviceType', 'DeviceInfo']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basándonos en el análisis exploratorio de datos (EDA) realizado previamente, eliminamos las columnas que contienen más del 80% de valores nulos.\n",
    "- Eliminamos las filas con valores nulos debido a que tenemos suficientes cantidad de registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['dist1','DeviceType','R_emaildomain','DeviceInfo','dist2'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud           0\n",
       "TransactionDT     0\n",
       "TransactionAmt    0\n",
       "ProductCD         0\n",
       "addr1             0\n",
       "addr2             0\n",
       "P_emaildomain     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es necesatio convertir los tipos de datos, debido a que son adecuado al tipo de datos que ya tienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud             int64\n",
       "TransactionDT       int64\n",
       "TransactionAmt    float64\n",
       "ProductCD          object\n",
       "addr1             float64\n",
       "addr2             float64\n",
       "P_emaildomain      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos datos características (X) y variable objetivo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('isFraud', axis=1)  # features\n",
    "y = data['isFraud']  # target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de nuevas características (feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionAmt_Range\n",
      "Medio       222081\n",
      "Bajo         96130\n",
      "Alto         69619\n",
      "Muy alto     44838\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calcular los cuartiles y el IQR\n",
    "Q1 = np.percentile(X['TransactionAmt'], 25)\n",
    "Q3 = np.percentile(X['TransactionAmt'], 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir los umbrales para valores atípicos\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Función para clasificar los valores en rangos\n",
    "def classify_transaction_amt(value):\n",
    "    if value < lower_bound:\n",
    "        return 'Muy bajo'\n",
    "    elif lower_bound <= value < Q1:\n",
    "        return 'Bajo'\n",
    "    elif Q1 <= value < Q3:\n",
    "        return 'Medio'\n",
    "    elif Q3 <= value < upper_bound:\n",
    "        return 'Alto'\n",
    "    else:\n",
    "        return 'Muy alto'\n",
    "\n",
    "# Aplicar la función de clasificación a la columna\n",
    "X['TransactionAmt_Range'] = X['TransactionAmt'].apply(classify_transaction_amt)\n",
    "\n",
    "\n",
    "# Mostrar algunos resultados\n",
    "print(X['TransactionAmt_Range'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos la columna 'TransactionAmt' por la conclusiones obtenidas en EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('TransactionAmt', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntar addr1 y addr2\n",
    "\n",
    "- addr1 representa una región dentro de un país, mientras que addr2 corresponde al código de país. Combinar estas variables podría capturar de manera más efectiva la relación geográfica entre regiones y países en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['addr1'] = X['addr1'].astype('int').astype('str')\n",
    "X['addr2'] = X['addr2'].astype('int').astype('str')\n",
    "\n",
    "# Concatenar addr1 y addr2 en una nueva columna addr_combined usando +\n",
    "X['addr_combined'] = X['addr1'] + '_' + X['addr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionDT', 'ProductCD', 'addr1', 'addr2', 'P_emaildomain',\n",
       "       'TransactionAmt_Range', 'addr_combined'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminamos addr1 y addr2 de X\n",
    "X.drop(['addr1', 'addr2'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionDT            int64\n",
       "ProductCD               object\n",
       "P_emaildomain           object\n",
       "TransactionAmt_Range    object\n",
       "addr_combined           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar tipos de datos\n",
    "data_types = X.dtypes\n",
    "\n",
    "# Filtrar y contar variables numéricas y categóricas\n",
    "num_vars = data_types[data_types != 'object']  # Variables numéricas\n",
    "cat_vars = data_types[data_types == 'object']  # Variables categóricas\n",
    "num_vars_names = num_vars.index.tolist()\n",
    "cat_vars_names = cat_vars.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: ProductCD, el número de variables es: 4\n",
      "Columna: P_emaildomain, el número de variables es: 59\n",
      "Columna: TransactionAmt_Range, el número de variables es: 4\n",
      "Columna: addr_combined, el número de variables es: 424\n"
     ]
    }
   ],
   "source": [
    "for columna in cat_vars_names :\n",
    "    print(f\"Columna: {columna}, el número de variables es: {X[columna].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que cada columna tiene diferentes tipos de categorías, aplicaremos según sea adecuada a cada cado.\n",
    "- ProductCD (4 categorías):\n",
    "    - One-Hot Encoding: Como ProductCD tiene un número pequeño y fijo de categorías (4 en total), el one-hot encoding es una opción adecuada. \n",
    "\n",
    "- TransactionAmt_Range (4 categorías):\n",
    "    - Dado que TransactionAmt_Range tiene un orden natural o ordinal con 4 categorías, el ordinal encoding es apropiado. Asigna valores numéricos secuenciales a cada categoría.\n",
    "- P_emaildomain (56 categorías) y  addr_combined:\n",
    "    - Hashing Trick o Binary Encoding:  Dado que P_emaildomain tiene muchas categorías (56), el one-hot encoding puede generar demasiadas columnas y aumentar la complejidad. binary encoding podrían ser más eficientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432668, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Codificación One-Hot para ProductCD\n",
    "encoder_productcd = OneHotEncoder()\n",
    "X_productcd_encoded = encoder_productcd.fit_transform(X[['ProductCD']])\n",
    "\n",
    "\n",
    "# Convertir la matriz dispersa a DataFrame y verificar su forma\n",
    "X_productcd_encoded_df = pd.DataFrame(X_productcd_encoded.toarray(), \n",
    "                                      columns=encoder_productcd.get_feature_names_out(['ProductCD']),\n",
    "                                      index=X.index)\n",
    "\n",
    "X.drop(['ProductCD'], axis=1,inplace=True)\n",
    "X  = pd.concat([X, X_productcd_encoded_df], axis=1)\n",
    "\n",
    "# Codificación Ordinal para TransactionAmt_Range\n",
    "encoder_transactionamt_range = OrdinalEncoder()\n",
    "X['TransactionAmt_Range'] = encoder_transactionamt_range.fit_transform(X[['TransactionAmt_Range']])\n",
    "\n",
    "# Codificación BinaryEncoder para 'P_emaildomain'\n",
    "encoder_pemaildomain = ce.BinaryEncoder(cols=['P_emaildomain'])\n",
    "X_encoded_pemaildomain = encoder_pemaildomain.fit_transform(X['P_emaildomain'])\n",
    "\n",
    "# Eliminar la columna original 'P_emaildomain' y concatenar las columnas codificadas\n",
    "X = pd.concat([X.drop(['P_emaildomain'], axis=1), X_encoded_pemaildomain], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Codificación BinaryEncoder para 'addr_combined'\n",
    "encoder_addr_combined = ce.BinaryEncoder(cols=['addr_combined'])\n",
    "X_encoded_addr_combined = encoder_addr_combined.fit_transform(X['addr_combined'])\n",
    "\n",
    "# Eliminar la columna original 'addr_combined' y concatenar las columnas codificadas\n",
    "X = pd.concat([X.drop(['addr_combined'], axis=1), X_encoded_addr_combined], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print( X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionDT', 'TransactionAmt_Range', 'ProductCD_C', 'ProductCD_H',\n",
       "       'ProductCD_R', 'ProductCD_W', 'P_emaildomain_0', 'P_emaildomain_1',\n",
       "       'P_emaildomain_2', 'P_emaildomain_3', 'P_emaildomain_4',\n",
       "       'P_emaildomain_5', 'addr_combined_0', 'addr_combined_1',\n",
       "       'addr_combined_2', 'addr_combined_3', 'addr_combined_4',\n",
       "       'addr_combined_5', 'addr_combined_6', 'addr_combined_7',\n",
       "       'addr_combined_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización y estandarización de las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basados en el anális EDA la columna 'TransactionDT' tiene una distribución casi uniforme por lo tanto la normalización Min-Max ajusta los valores de una característica a un rango específico, típicamente entre 0 y 1. Es útil cuando deseas mantener la distribución de los datos pero ajustarla a una escala uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ajustar y transformar los datos de TransactionDT\n",
    "X['TransactionDT_scaled'] = scaler.fit_transform(X[['TransactionDT']])\n",
    "X.drop('TransactionDT',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En este proyecto de Data Science, el proceso de limpieza y preprocesamiento de datos ha sido fundamental para preparar nuestros datos antes de aplicar modelos de aprendizaje automático. A continuación, se detallan las principales etapas y decisiones tomadas durante este proceso:\n",
    "\n",
    "1. **Selección Estratégica del Dataset**: Se cargó el dataset completo y se seleccionó estratégicamente una porción del 10%, utilizando muestreo estratificado para asegurar representatividad y evitar sesgos en nuestros modelos.\n",
    "\n",
    "2. **Selección de Características Relevantes**: Se llevó a cabo la selección de las columnas más relevantes para nuestro análisis y modelos, descartando aquellas que no contribuían significativamente a la predicción del target.\n",
    "\n",
    "3. **Manejo de Valores Nulos**: Se eliminaron aquellas columnas que contenían un alto porcentaje (mayor al 80%) de valores nulos, así como las filas con un porcentaje bajo de valores nulos para garantizar la integridad de los datos restantes.\n",
    "\n",
    "4. **Separación de Variables**: Se realizó una clara separación entre las variables características (`X`) y el target (`y`), asegurando que estuvieran correctamente definidas para el entrenamiento de los modelos.\n",
    "\n",
    "5. **Ingeniería de Características**: Basados en un análisis exploratorio de datos (EDA), se reemplazó la columna `TransactionAmt` por `TransactionAmt_Range`, una variable categórica que agrupa los valores en rangos como \"muy bajo\", \"bajo\", \"medio\", \"alto\" y \"muy alto\". Esta transformación facilita el manejo de variables con amplios rangos de valores, evitando posibles complicaciones durante el entrenamiento de los modelos.\n",
    "\n",
    "6. **Combinación de Variables**: Se combinaron las columnas `addr1` y `addr2` en una sola columna (`addr_combined`), reduciendo así la dimensionalidad del dataset sin perder información relevante.\n",
    "\n",
    "7. **Codificación de Variables Categóricas**: Se aplicaron técnicas adecuadas de codificación a las variables categóricas según su naturaleza, como codificación one-hot y binary encoding, para prepararlas para su uso en los modelos de aprendizaje automático.\n",
    "\n",
    "8. **Normalización de Variables Numéricas**: Se normalizaron las variables numéricas para asegurar que todas estuvieran en la misma escala, lo cual es crucial para modelos que se basan en la distancia o magnitud de los atributos.\n",
    "\n",
    "En resumen, el proceso de limpieza y preprocesamiento de datos realizado ha permitido transformar el dataset inicial en un formato apto y optimizado para la construcción de modelos predictivos. Estas etapas son fundamentales para asegurar la calidad de los resultados obtenidos y facilitar la interpretación y aplicación de los modelos en la práctica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar X y y en archivos CSV\n",
    "\n",
    "dir_data_processed = '../data/processed'\n",
    "ruta_archivo_X = os.path.join(dir_data_processed, 'datos_procesados.csv')\n",
    "X.to_csv(ruta_archivo_X, index=False, encoding='utf-8')\n",
    "\n",
    "ruta_archivo_y = os.path.join(dir_data_processed, 'target.csv')\n",
    "y.to_csv(ruta_archivo_y, index=False, encoding='utf-8')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
