{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Data Cleaning and Preprocessing\n",
    "**Objetivo**: Limpiar y preprocesar los datos para que estén listos para el modelado.\n",
    "**Contenido**:\n",
    "- Manejo de valores nulos.\n",
    "- Creación de nuevas características (feature engineering).\n",
    "- Conversión de tipos de datos.\n",
    "- Codificación de variables categóricas.\n",
    "- Normalización y estandarización de las variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Librerías \n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cargamos los Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trabajaremos exclusivamente con el dataset de entrenamiento \"train_transaction\" para obtener tanto los datos de entrenamiento como los de validación. De este dataset solo tomaremos el 10 % del total de los registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_col_transaction = 'TransactionID,isFraud,TransactionDT,TransactionAmt,ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,dist1,dist2,P_emaildomain,R_emaildomain,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,D1,D2,D3,D4,D5,D6,D7,D8,D9,D10,D11,D12,D13,D14,D15,M1,M2,M3,M4,M5,M6,M7,M8,M9'.split(',')\n",
    "select_col_identity = 'TransactionID,id_01,id_02,id_03,id_04,id_05,id_06,id_07,id_08,id_09,id_10,id_11,id_12,id_13,id_14,id_15,id_16,id_17,id_18,id_19,id_20,id_21,id_22,id_23,id_24,id_25,id_26,id_27,id_28,id_29,id_30,id_31,id_32,id_33,id_34,id_35,id_36,id_37,id_38,DeviceType,DeviceInfo'.split(',')\n",
    "data_dir = '../data/raw/ieee-fraud-detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de porción del Dataset de entrenamiento con Muestreo Estratificado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Data columns (total 95 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   TransactionID   590540 non-null  int64  \n",
      " 1   isFraud         590540 non-null  int64  \n",
      " 2   TransactionDT   590540 non-null  int64  \n",
      " 3   TransactionAmt  590540 non-null  float64\n",
      " 4   ProductCD       590540 non-null  object \n",
      " 5   card1           590540 non-null  int64  \n",
      " 6   card2           581607 non-null  float64\n",
      " 7   card3           588975 non-null  float64\n",
      " 8   card4           588963 non-null  object \n",
      " 9   card5           586281 non-null  float64\n",
      " 10  card6           588969 non-null  object \n",
      " 11  addr1           524834 non-null  float64\n",
      " 12  addr2           524834 non-null  float64\n",
      " 13  dist1           238269 non-null  float64\n",
      " 14  dist2           37627 non-null   float64\n",
      " 15  P_emaildomain   496084 non-null  object \n",
      " 16  R_emaildomain   137291 non-null  object \n",
      " 17  C1              590540 non-null  float64\n",
      " 18  C2              590540 non-null  float64\n",
      " 19  C3              590540 non-null  float64\n",
      " 20  C4              590540 non-null  float64\n",
      " 21  C5              590540 non-null  float64\n",
      " 22  C6              590540 non-null  float64\n",
      " 23  C7              590540 non-null  float64\n",
      " 24  C8              590540 non-null  float64\n",
      " 25  C9              590540 non-null  float64\n",
      " 26  C10             590540 non-null  float64\n",
      " 27  C11             590540 non-null  float64\n",
      " 28  C12             590540 non-null  float64\n",
      " 29  C13             590540 non-null  float64\n",
      " 30  C14             590540 non-null  float64\n",
      " 31  D1              589271 non-null  float64\n",
      " 32  D2              309743 non-null  float64\n",
      " 33  D3              327662 non-null  float64\n",
      " 34  D4              421618 non-null  float64\n",
      " 35  D5              280699 non-null  float64\n",
      " 36  D6              73187 non-null   float64\n",
      " 37  D7              38917 non-null   float64\n",
      " 38  D8              74926 non-null   float64\n",
      " 39  D9              74926 non-null   float64\n",
      " 40  D10             514518 non-null  float64\n",
      " 41  D11             311253 non-null  float64\n",
      " 42  D12             64717 non-null   float64\n",
      " 43  D13             61952 non-null   float64\n",
      " 44  D14             62187 non-null   float64\n",
      " 45  D15             501427 non-null  float64\n",
      " 46  M1              319440 non-null  object \n",
      " 47  M2              319440 non-null  object \n",
      " 48  M3              319440 non-null  object \n",
      " 49  M4              309096 non-null  object \n",
      " 50  M5              240058 non-null  object \n",
      " 51  M6              421180 non-null  object \n",
      " 52  M7              244275 non-null  object \n",
      " 53  M8              244288 non-null  object \n",
      " 54  M9              244288 non-null  object \n",
      " 55  id_01           144233 non-null  float64\n",
      " 56  id_02           140872 non-null  float64\n",
      " 57  id_03           66324 non-null   float64\n",
      " 58  id_04           66324 non-null   float64\n",
      " 59  id_05           136865 non-null  float64\n",
      " 60  id_06           136865 non-null  float64\n",
      " 61  id_07           5155 non-null    float64\n",
      " 62  id_08           5155 non-null    float64\n",
      " 63  id_09           74926 non-null   float64\n",
      " 64  id_10           74926 non-null   float64\n",
      " 65  id_11           140978 non-null  float64\n",
      " 66  id_12           144233 non-null  object \n",
      " 67  id_13           127320 non-null  float64\n",
      " 68  id_14           80044 non-null   float64\n",
      " 69  id_15           140985 non-null  object \n",
      " 70  id_16           129340 non-null  object \n",
      " 71  id_17           139369 non-null  float64\n",
      " 72  id_18           45113 non-null   float64\n",
      " 73  id_19           139318 non-null  float64\n",
      " 74  id_20           139261 non-null  float64\n",
      " 75  id_21           5159 non-null    float64\n",
      " 76  id_22           5169 non-null    float64\n",
      " 77  id_23           5169 non-null    object \n",
      " 78  id_24           4747 non-null    float64\n",
      " 79  id_25           5132 non-null    float64\n",
      " 80  id_26           5163 non-null    float64\n",
      " 81  id_27           5169 non-null    object \n",
      " 82  id_28           140978 non-null  object \n",
      " 83  id_29           140978 non-null  object \n",
      " 84  id_30           77565 non-null   object \n",
      " 85  id_31           140282 non-null  object \n",
      " 86  id_32           77586 non-null   float64\n",
      " 87  id_33           73289 non-null   object \n",
      " 88  id_34           77805 non-null   object \n",
      " 89  id_35           140985 non-null  object \n",
      " 90  id_36           140985 non-null  object \n",
      " 91  id_37           140985 non-null  object \n",
      " 92  id_38           140985 non-null  object \n",
      " 93  DeviceType      140810 non-null  object \n",
      " 94  DeviceInfo      118666 non-null  object \n",
      "dtypes: float64(60), int64(4), object(31)\n",
      "memory usage: 428.0+ MB\n"
     ]
    }
   ],
   "source": [
    "## dataset de entrenamiento\n",
    "seed = 42\n",
    "# Cargar los datos\n",
    "df_transaction_train = pd.read_csv(data_dir + '/train_transaction.csv', usecols=select_col_transaction)\n",
    "df_identity_train = pd.read_csv(data_dir + '/train_identity.csv', usecols=select_col_identity)\n",
    "\n",
    "# Combinar los datasets\n",
    "dataset = pd.merge(df_transaction_train, df_identity_train, on='TransactionID', how='left')\n",
    "\n",
    "# Realizar el muestreo estratificado\n",
    "#data, _ = train_test_split(dataset, stratify=dataset['isFraud'], test_size=0.9, random_state=seed)\n",
    "data = dataset\n",
    "# Mostrar la información del dataset resultante\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armamos un nuevo dataset con las columnas más relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['isFraud', 'TransactionDT', 'TransactionAmt',\n",
    "       'ProductCD','addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain',\n",
    "       'DeviceType', 'DeviceInfo','card1', 'card2', 'card3', 'card4', 'card5', 'card6',]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basándonos en el análisis exploratorio de datos (EDA) realizado previamente, eliminamos las columnas que contienen más del 80% de valores nulos.\n",
    "- Eliminamos las filas con valores nulos debido a que tenemos suficientes cantidad de registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['DeviceType','R_emaildomain','DeviceInfo','dist2'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud           0\n",
       "TransactionDT     0\n",
       "TransactionAmt    0\n",
       "ProductCD         0\n",
       "addr1             0\n",
       "addr2             0\n",
       "dist1             0\n",
       "P_emaildomain     0\n",
       "card1             0\n",
       "card2             0\n",
       "card3             0\n",
       "card4             0\n",
       "card5             0\n",
       "card6             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isFraud           0.0\n",
      "TransactionDT     0.0\n",
      "TransactionAmt    0.0\n",
      "ProductCD         0.0\n",
      "addr1             0.0\n",
      "addr2             0.0\n",
      "dist1             0.0\n",
      "P_emaildomain     0.0\n",
      "card1             0.0\n",
      "card2             0.0\n",
      "card3             0.0\n",
      "card4             0.0\n",
      "card5             0.0\n",
      "card6             0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "null_percentages = (data.isnull().sum() / len(data)) * 100\n",
    "print(round(null_percentages,2).sort_values(ascending=True).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187502, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es necesatio convertir los tipos de datos, debido a que son adecuado al tipo de datos que ya tienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud             int64\n",
       "TransactionDT       int64\n",
       "TransactionAmt    float64\n",
       "ProductCD          object\n",
       "addr1             float64\n",
       "addr2             float64\n",
       "dist1             float64\n",
       "P_emaildomain      object\n",
       "card1               int64\n",
       "card2             float64\n",
       "card3             float64\n",
       "card4              object\n",
       "card5             float64\n",
       "card6              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos datos características (X) y variable objetivo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('isFraud', axis=1)  # features\n",
    "y = data['isFraud']  # target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de nuevas características (feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Calcular los cuartiles y el IQR\n",
    "# Q1 = np.percentile(X['TransactionAmt'], 25)\n",
    "# Q3 = np.percentile(X['TransactionAmt'], 75)\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# # Definir los umbrales para valores atípicos\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# # Función para clasificar los valores en rangos\n",
    "# def classify_transaction_amt(value):\n",
    "#     if value < lower_bound:\n",
    "#         return 'Muy bajo'\n",
    "#     elif lower_bound <= value < Q1:\n",
    "#         return 'Bajo'\n",
    "#     elif Q1 <= value < Q3:\n",
    "#         return 'Medio'\n",
    "#     elif Q3 <= value < upper_bound:\n",
    "#         return 'Alto'\n",
    "#     else:\n",
    "#         return 'Muy alto'\n",
    "\n",
    "# # Aplicar la función de clasificación a la columna\n",
    "# X['TransactionAmt_Range'] = X['TransactionAmt'].apply(classify_transaction_amt)\n",
    "\n",
    "\n",
    "# # Mostrar algunos resultados\n",
    "# print(X['TransactionAmt_Range'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos la columna 'TransactionAmt' por la conclusiones obtenidas en EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop('TransactionAmt', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntar addr1 y addr2\n",
    "\n",
    "- addr1 representa una región dentro de un país, mientras que addr2 corresponde al código de país. Combinar estas variables podría capturar de manera más efectiva la relación geográfica entre regiones y países en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['addr1'] = X['addr1'].astype('int').astype('str')\n",
    "X['addr2'] = X['addr2'].astype('int').astype('str')\n",
    "\n",
    "# Concatenar addr1 y addr2 en una nueva columna addr_combined usando +\n",
    "X['addr_combined'] = X['addr1'] + '_' + X['addr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionDT', 'TransactionAmt', 'ProductCD', 'addr1', 'addr2',\n",
       "       'dist1', 'P_emaildomain', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
       "       'card6', 'addr_combined'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminamos addr1 y addr2 de X\n",
    "X.drop(['addr1', 'addr2'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionDT       int64\n",
       "TransactionAmt    float64\n",
       "ProductCD          object\n",
       "dist1             float64\n",
       "P_emaildomain      object\n",
       "card1               int64\n",
       "card2             float64\n",
       "card3             float64\n",
       "card4              object\n",
       "card5             float64\n",
       "card6              object\n",
       "addr_combined      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar tipos de datos\n",
    "data_types = X.dtypes\n",
    "\n",
    "# Filtrar y contar variables numéricas y categóricas\n",
    "num_vars = data_types[data_types != 'object']  # Variables numéricas\n",
    "cat_vars = data_types[data_types == 'object']  # Variables categóricas\n",
    "num_vars_names = num_vars.index.tolist()\n",
    "cat_vars_names = cat_vars.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: ProductCD, el número de variables es: 1\n",
      "Columna: P_emaildomain, el número de variables es: 51\n",
      "Columna: card4, el número de variables es: 3\n",
      "Columna: card6, el número de variables es: 3\n",
      "Columna: addr_combined, el número de variables es: 89\n"
     ]
    }
   ],
   "source": [
    "for columna in cat_vars_names :\n",
    "    print(f\"Columna: {columna}, el número de variables es: {X[columna].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que cada columna tiene diferentes tipos de categorías, aplicaremos según sea adecuada a cada cado.\n",
    "- ProductCD (4 categorías):\n",
    "    - One-Hot Encoding: Como ProductCD tiene un número pequeño y fijo de categorías (4 en total), el one-hot encoding es una opción adecuada. \n",
    "\n",
    "- TransactionAmt_Range (4 categorías):\n",
    "    - Dado que TransactionAmt_Range tiene un orden natural o ordinal con 4 categorías, el ordinal encoding es apropiado. Asigna valores numéricos secuenciales a cada categoría.\n",
    "- P_emaildomain (56 categorías) y  addr_combined:\n",
    "    - Hashing Trick o Binary Encoding:  Dado que P_emaildomain tiene muchas categorías (56), el one-hot encoding puede generar demasiadas columnas y aumentar la complejidad. binary encoding podrían ser más eficientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187502, 29)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Codificación One-Hot para ProductCD\n",
    "encoder_productcd = OneHotEncoder()\n",
    "X_productcd_encoded = encoder_productcd.fit_transform(X[['ProductCD','card4','card6']])\n",
    "\n",
    "\n",
    "# Convertir la matriz dispersa a DataFrame y verificar su forma\n",
    "X_productcd_encoded_df = pd.DataFrame(X_productcd_encoded.toarray(), \n",
    "                                      columns=encoder_productcd.get_feature_names_out(['ProductCD','card4','card6']),\n",
    "                                      index=X.index)\n",
    "\n",
    "X.drop(['ProductCD'], axis=1,inplace=True)\n",
    "X  = pd.concat([X, X_productcd_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Codificación Ordinal para TransactionAmt_Range\n",
    "# encoder_transactionamt_range = OrdinalEncoder()\n",
    "# X['TransactionAmt_Range'] = encoder_transactionamt_range.fit_transform(X[['TransactionAmt_Range']])\n",
    "\n",
    "# Codificación BinaryEncoder para 'P_emaildomain'\n",
    "encoder_pemaildomain = ce.BinaryEncoder(cols=['P_emaildomain'])\n",
    "X_encoded_pemaildomain = encoder_pemaildomain.fit_transform(X['P_emaildomain'])\n",
    "\n",
    "# Eliminar la columna original 'P_emaildomain' y concatenar las columnas codificadas\n",
    "X = pd.concat([X.drop(['P_emaildomain'], axis=1), X_encoded_pemaildomain], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Codificación BinaryEncoder para 'addr_combined'\n",
    "encoder_addr_combined = ce.BinaryEncoder(cols=['addr_combined'])\n",
    "X_encoded_addr_combined = encoder_addr_combined.fit_transform(X['addr_combined'])\n",
    "\n",
    "# Eliminar la columna original 'addr_combined' y concatenar las columnas codificadas\n",
    "X = pd.concat([X.drop(['addr_combined'], axis=1), X_encoded_addr_combined], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print( X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionDT', 'TransactionAmt', 'dist1', 'card1', 'card2', 'card3',\n",
       "       'card4', 'card5', 'card6', 'ProductCD_W', 'card4_discover',\n",
       "       'card4_mastercard', 'card4_visa', 'card6_credit', 'card6_debit',\n",
       "       'card6_debit or credit', 'P_emaildomain_0', 'P_emaildomain_1',\n",
       "       'P_emaildomain_2', 'P_emaildomain_3', 'P_emaildomain_4',\n",
       "       'P_emaildomain_5', 'addr_combined_0', 'addr_combined_1',\n",
       "       'addr_combined_2', 'addr_combined_3', 'addr_combined_4',\n",
       "       'addr_combined_5', 'addr_combined_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización y estandarización de las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basados en el anális EDA la columna 'TransactionDT' tiene una distribución casi uniforme por lo tanto la normalización Min-Max ajusta los valores de una característica a un rango específico, típicamente entre 0 y 1. Es útil cuando deseas mantener la distribución de los datos pero ajustarla a una escala uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionDT', 'TransactionAmt', 'dist1', 'card1', 'card2', 'card3',\n",
       "       'card4', 'card5', 'card6', 'ProductCD_W', 'card4_discover',\n",
       "       'card4_mastercard', 'card4_visa', 'card6_credit', 'card6_debit',\n",
       "       'card6_debit or credit', 'P_emaildomain_0', 'P_emaildomain_1',\n",
       "       'P_emaildomain_2', 'P_emaildomain_3', 'P_emaildomain_4',\n",
       "       'P_emaildomain_5', 'addr_combined_0', 'addr_combined_1',\n",
       "       'addr_combined_2', 'addr_combined_3', 'addr_combined_4',\n",
       "       'addr_combined_5', 'addr_combined_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar MinMaxScaler a las columnas específicas\n",
    "scaler_min_max = MinMaxScaler()\n",
    "X[['TransactionDT', 'card1', 'card2', 'card3', 'card5']] = scaler_min_max.fit_transform(X[['TransactionDT', 'card1', 'card2', 'card3', 'card5']])\n",
    "\n",
    "\n",
    "# Aplicar RobustScaler a 'TransactionAmt'\n",
    "scaler_robust = RobustScaler()\n",
    "X['TransactionAmt'] = scaler_robust.fit_transform(X[['TransactionAmt']])\n",
    "\n",
    "# Aplicar StandardScaler a 'dist1'\n",
    "scaler_standard = StandardScaler()\n",
    "X['dist1'] = scaler_standard.fit_transform(X[['dist1']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>dist1</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>ProductCD_W</th>\n",
       "      <th>...</th>\n",
       "      <th>P_emaildomain_3</th>\n",
       "      <th>P_emaildomain_4</th>\n",
       "      <th>P_emaildomain_5</th>\n",
       "      <th>addr_combined_0</th>\n",
       "      <th>addr_combined_1</th>\n",
       "      <th>addr_combined_2</th>\n",
       "      <th>addr_combined_3</th>\n",
       "      <th>addr_combined_4</th>\n",
       "      <th>addr_combined_5</th>\n",
       "      <th>addr_combined_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.227835</td>\n",
       "      <td>0.429246</td>\n",
       "      <td>0.210532</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>visa</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>debit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.330928</td>\n",
       "      <td>-0.230151</td>\n",
       "      <td>0.283776</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>visa</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>debit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.803093</td>\n",
       "      <td>-0.324726</td>\n",
       "      <td>0.650052</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>visa</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>debit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.370103</td>\n",
       "      <td>-0.274811</td>\n",
       "      <td>0.942739</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>debit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.341753</td>\n",
       "      <td>-0.311591</td>\n",
       "      <td>0.210532</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>visa</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>debit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TransactionDT  TransactionAmt     dist1     card1  card2     card3  \\\n",
       "2        0.000000       -0.227835  0.429246  0.210532  0.780  0.381679   \n",
       "5        0.000003       -0.330928 -0.230151  0.283776  0.910  0.381679   \n",
       "6        0.000003        0.803093 -0.324726  0.650052  0.520  0.381679   \n",
       "9        0.000004        0.370103 -0.274811  0.942739  0.022  0.381679   \n",
       "18       0.000016       -0.341753 -0.311591  0.210532  0.780  0.381679   \n",
       "\n",
       "         card4     card5  card6  ProductCD_W  ...  P_emaildomain_3  \\\n",
       "2         visa  0.488889  debit          1.0  ...                0   \n",
       "5         visa  0.933333  debit          1.0  ...                0   \n",
       "6         visa  0.488889  debit          1.0  ...                0   \n",
       "9   mastercard  0.918519  debit          1.0  ...                0   \n",
       "18        visa  0.488889  debit          1.0  ...                0   \n",
       "\n",
       "    P_emaildomain_4  P_emaildomain_5  addr_combined_0  addr_combined_1  \\\n",
       "2                 0                1                0                0   \n",
       "5                 1                0                0                0   \n",
       "6                 1                1                0                0   \n",
       "9                 1                1                0                0   \n",
       "18                1                0                0                0   \n",
       "\n",
       "    addr_combined_2  addr_combined_3  addr_combined_4  addr_combined_5  \\\n",
       "2                 0                0                0                0   \n",
       "5                 0                0                0                1   \n",
       "6                 0                0                0                1   \n",
       "9                 0                0                1                0   \n",
       "18                0                0                1                0   \n",
       "\n",
       "    addr_combined_6  \n",
       "2                 1  \n",
       "5                 0  \n",
       "6                 1  \n",
       "9                 0  \n",
       "18                1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En este proyecto de Data Science, el proceso de limpieza y preprocesamiento de datos ha sido fundamental para preparar nuestros datos antes de aplicar modelos de aprendizaje automático. A continuación, se detallan las principales etapas y decisiones tomadas durante este proceso:\n",
    "\n",
    "1. **Selección Estratégica del Dataset**: Se cargó el dataset completo y se seleccionó estratégicamente una porción del 10%, utilizando muestreo estratificado para asegurar representatividad y evitar sesgos en nuestros modelos.\n",
    "\n",
    "2. **Selección de Características Relevantes**: Se llevó a cabo la selección de las columnas más relevantes para nuestro análisis y modelos, descartando aquellas que no contribuían significativamente a la predicción del target.\n",
    "\n",
    "3. **Manejo de Valores Nulos**: Se eliminaron aquellas columnas que contenían un alto porcentaje (mayor al 80%) de valores nulos, así como las filas con un porcentaje bajo de valores nulos para garantizar la integridad de los datos restantes.\n",
    "\n",
    "4. **Separación de Variables**: Se realizó una clara separación entre las variables características (`X`) y el target (`y`), asegurando que estuvieran correctamente definidas para el entrenamiento de los modelos.\n",
    "\n",
    "5. **Ingeniería de Características**: Basados en un análisis exploratorio de datos (EDA), se reemplazó la columna `TransactionAmt` por `TransactionAmt_Range`, una variable categórica que agrupa los valores en rangos como \"muy bajo\", \"bajo\", \"medio\", \"alto\" y \"muy alto\". Esta transformación facilita el manejo de variables con amplios rangos de valores, evitando posibles complicaciones durante el entrenamiento de los modelos.\n",
    "\n",
    "6. **Combinación de Variables**: Se combinaron las columnas `addr1` y `addr2` en una sola columna (`addr_combined`), reduciendo así la dimensionalidad del dataset sin perder información relevante.\n",
    "\n",
    "7. **Codificación de Variables Categóricas**: Se aplicaron técnicas adecuadas de codificación a las variables categóricas según su naturaleza, como codificación one-hot y binary encoding, para prepararlas para su uso en los modelos de aprendizaje automático.\n",
    "\n",
    "8. **Normalización de Variables Numéricas**: Se normalizaron las variables numéricas para asegurar que todas estuvieran en la misma escala, lo cual es crucial para modelos que se basan en la distancia o magnitud de los atributos.\n",
    "\n",
    "En resumen, el proceso de limpieza y preprocesamiento de datos realizado ha permitido transformar el dataset inicial en un formato apto y optimizado para la construcción de modelos predictivos. Estas etapas son fundamentales para asegurar la calidad de los resultados obtenidos y facilitar la interpretación y aplicación de los modelos en la práctica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar X y y en archivos CSV\n",
    "\n",
    "dir_data_processed = '../data/processed'\n",
    "ruta_archivo_X = os.path.join(dir_data_processed, 'datos_procesados.csv')\n",
    "X.to_csv(ruta_archivo_X, index=False, encoding='utf-8')\n",
    "\n",
    "ruta_archivo_y = os.path.join(dir_data_processed, 'target.csv')\n",
    "y.to_csv(ruta_archivo_y, index=False, encoding='utf-8')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
