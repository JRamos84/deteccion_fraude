{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JRamos84/deteccion_fraude/blob/main/notebooks/04_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSXYXGue95ek"
      },
      "source": [
        "\n",
        "## 04 Modeling\n",
        "**Objetivo**: Construir y evaluar modelos de clasificación.\n",
        "**Contenido**:\n",
        "\n",
        "- Carga y preparación de los datos\n",
        "- División de los datos en conjuntos de entrenamiento y prueba\n",
        "- Entrenamiento de modelos\n",
        "- Evaluación de los modelos\n",
        "- Comparación de resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "E_Cd8Scv95en"
      },
      "outputs": [],
      "source": [
        "##  Importación de Librerías\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_and_evaluate_model(model, X_train, y_train, X_val, y_val, cv=5):\n",
        "    # Asegúrate de que y_train y y_val sean vectores unidimensionales\n",
        "    y_train = np.ravel(y_train)\n",
        "    y_val = np.ravel(y_val)\n",
        "\n",
        "    # Validación cruzada en el conjunto de entrenamiento\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "    y_train_pred_cv = cross_val_predict(model, X_train, y_train, cv=cv)\n",
        "\n",
        "    # Calcular métricas de validación cruzada\n",
        "    accuracy_cv = cv_scores.mean()\n",
        "    roc_auc_cv = roc_auc_score(y_train, y_train_pred_cv)\n",
        "\n",
        "    # Imprimir métricas de validación cruzada\n",
        "    print(f'Accuracy (CV): {accuracy_cv:.4f}')\n",
        "    print(f'ROC AUC (CV): {roc_auc_cv:.4f}')\n",
        "    print('Classification Report (CV):')\n",
        "    print(classification_report(y_train, y_train_pred_cv))\n",
        "\n",
        "    # Mostrar la matriz de confusión promediada\n",
        "    conf_matrix_cv = confusion_matrix(y_train, y_train_pred_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix_cv, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix (CV)')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Entrenar el modelo con los datos de entrenamiento completos\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predecir con los datos de validación\n",
        "    y_val_pred = model.predict(X_val)\n",
        "\n",
        "    # Calcular métricas en el conjunto de validación\n",
        "    accuracy_val = accuracy_score(y_val, y_val_pred)\n",
        "    roc_auc_val = roc_auc_score(y_val, y_val_pred)\n",
        "\n",
        "    # Imprimir métricas del conjunto de validación\n",
        "    print(f'Accuracy (Validation): {accuracy_val:.4f}')\n",
        "    print(f'ROC AUC (Validation): {roc_auc_val:.4f}')\n",
        "    print('Classification Report (Validation):')\n",
        "    print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "    # Mostrar la matriz de confusión del conjunto de validación\n",
        "    conf_matrix_val = confusion_matrix(y_val, y_val_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix_val, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix (Validation)')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Retornar el modelo entrenado\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_xgboost_model(X_train, y_train, X_val, y_val, params, num_rounds=100, threshold=0.5):\n",
        "    # Convertir datos a DMatrix (formato optimizado para XGBoost)\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    model = xgb.train(params, dtrain, num_rounds)\n",
        "\n",
        "    # Predecir probabilidades en el conjunto de validación\n",
        "    y_pred_proba = model.predict(dval)\n",
        "\n",
        "    # Convertir probabilidades a etiquetas binarias\n",
        "    y_pred_binary = [1 if p > threshold else 0 for p in y_pred_proba]\n",
        "\n",
        "    # Calcular la precisión en el conjunto de validación\n",
        "    accuracy = accuracy_score(y_val, y_pred_binary)\n",
        "    print(f'Precisión en el conjunto de validación (Accuracy): {accuracy:.2f}')\n",
        "\n",
        "    # Calcular el área bajo la curva ROC (ROC AUC)\n",
        "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
        "    print(f'Área bajo la curva ROC (ROC AUC): {roc_auc:.2f}')\n",
        "\n",
        "    # Imprimir el reporte de clasificación en el conjunto de validación\n",
        "    print('Classification Report (Validation):')\n",
        "    print(classification_report(y_val, y_pred_binary))\n",
        "\n",
        "    # Mostrar la matriz de confusión en el conjunto de validación\n",
        "    conf_matrix = confusion_matrix(y_val, y_pred_binary)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Matriz de Confusión (Validation)')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3pbnpLEdRtN-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importamos las librerias a usar\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection'\n"
      ],
      "metadata": {
        "id": "c_QACNQ--Ipl",
        "outputId": "af5c9b45-cf6e-423a-f1de-44f7611cbc42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAqeD-ec95ep"
      },
      "source": [
        "## Carga y Preparación de los Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SVhaBBql95eq"
      },
      "outputs": [],
      "source": [
        "# Guardar X y y en archivos CSV\n",
        "\n",
        "#dir_data_processed = '../data/processed'\n",
        "dir_data_processed = '/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection/processed'\n",
        "ruta_archivo_X_train = os.path.join(dir_data_processed, 'X__train_procesados.csv')\n",
        "ruta_archivo_X_test = os.path.join(dir_data_processed, 'X_test_procesados.csv')\n",
        "ruta_archivo_X_val = os.path.join(dir_data_processed, 'X_val_procesados.csv')\n",
        "\n",
        "ruta_archivo_y_train = os.path.join(dir_data_processed, 'y_train_procesados.csv')\n",
        "ruta_archivo_y_test = os.path.join(dir_data_processed, 'y_test_procesados.csv')\n",
        "ruta_archivo_y_val = os.path.join(dir_data_processed, 'y_val_procesados.csv')\n",
        "\n",
        "\n",
        "X_train_final= pd.read_csv(ruta_archivo_X_train)\n",
        "X_val_final= pd.read_csv(ruta_archivo_X_val)\n",
        "X_test_final= pd.read_csv(ruta_archivo_X_test)\n",
        "\n",
        "y_train_final= pd.read_csv(ruta_archivo_y_train)\n",
        "y_val_final= pd.read_csv(ruta_archivo_y_val)\n",
        "y_test_final= pd.read_csv(ruta_archivo_y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AIyaIS-d95eq",
        "outputId": "f4fe92be-aa4d-4a67-adbc-a4f79601483e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(242811, 184)\n",
            "(52031, 184)\n",
            "(52032, 184)\n",
            "(242811, 1)\n",
            "(52031, 1)\n",
            "(52032, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_final.shape)\n",
        "print(X_val_final.shape)\n",
        "print(X_test_final.shape)\n",
        "\n",
        "print(y_train_final.shape)\n",
        "print(y_val_final.shape)\n",
        "print(y_test_final.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recuperación de lista de nombres de columnas por *Feature Selection*"
      ],
      "metadata": {
        "id": "JRjpTbPKvi15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_data_processed = '/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection/processed'\n",
        "ruta_archivo_columns = os.path.join(dir_data_processed, 'columns_feature_selection.pkl')\n",
        "with open(ruta_archivo_columns, 'rb') as file:\n",
        "    cat_cols_selected , col_selected_num = pickle.load(file)\n",
        "\n",
        "print('num_cols_feature_selection:', col_selected_num )\n",
        "print('cat_cols_feature_selection:', cat_cols_selected )\n"
      ],
      "metadata": {
        "id": "c9sb_F4KvsBj",
        "outputId": "fbe4e849-c6f4-4ad6-91e5-d485864fd7d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_cols_feature_selection: ['V283', 'V281', 'V280', 'V282', 'V279', 'V295', 'V308', 'V293', 'V312', 'V307', 'V95', 'V292', 'V97', 'V315', 'V318', 'V289', 'V317', 'V128', 'V101', 'V103', 'V62', 'V291', 'V294', 'V313', 'V314', 'V56', 'V288', 'V29', 'V131', 'V90', 'V69', 'V284', 'V30', 'V127', 'V91', 'V74', 'V70', 'V134', 'V290', 'V133', 'V287', 'V67', 'V33', 'V34', 'V94', 'V309', 'V98', 'V310', 'V102', 'V306', 'V73', 'V78', 'V83', 'V100', 'V55', 'V316', 'TransactionAmt', 'V96', 'V20', 'V126', 'V296', 'V298', 'V61', 'V130', 'V129', 'V54', 'V132']\n",
            "cat_cols_feature_selection: ['card6', '_Days', '_Hours']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(col_selected_num) + len(cat_cols_selected)"
      ],
      "metadata": {
        "id": "Wgko9sc1BFMl",
        "outputId": "280b582a-2934-42b9-a3ca-a126ebb5ec21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balanceo de muestra"
      ],
      "metadata": {
        "id": "X4sXmj3qpbqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Balanceo de X_train y y_train totales\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_B, y_train_B,= undersampler.fit_resample(X_train_final, y_train_final)\n",
        "# Mostrar la distribución de clases después del submuestreo\n",
        "X_train_B.shape, y_train_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71DbXLefkxbL",
        "outputId": "5af154e2-26ef-4eaa-d996-156f4a82c095"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9716, 184), (9716, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_B, return_counts=True)\n",
        "\n",
        "# Crear un diccionario para mostrar los resultados\n",
        "value_counts = dict(zip(unique, counts))\n",
        "print(value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y01rozuikyj4",
        "outputId": "719806ca-dda7-4e4e-c086-f1b550b0576f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 4858, 1: 4858}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_data_preprocessing='/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection/preprocessing_objects'\n",
        "pca = joblib.load(os.path.join(dir_data_preprocessing, 'pca.joblib'))\n",
        "X_train_pca_B = pca.transform(X_train_B)\n",
        "X_val_pca_B = pca.transform(X_val_final)"
      ],
      "metadata": {
        "id": "7zPy_pVmkd-O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparación de modelos de entrenamiento"
      ],
      "metadata": {
        "id": "2ckgL4sWWhcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir los modelos\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=10000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "# Evaluar cada modelo con validación cruzada\n",
        "for name, model in models.items():\n",
        "    # Calcular Accuracy\n",
        "    start_time = time.time()\n",
        "    accuracy_scores = cross_val_score(model, X_train_pca_B, np.ravel(y_train_B), cv=5, scoring='accuracy')\n",
        "\n",
        "    # Calcular ROC AUC\n",
        "    roc_auc_scores = cross_val_score(model, X_train_pca_B, np.ravel(y_train_B), cv=5, scoring='roc_auc')\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Accuracy: {accuracy_scores.mean():.4f} ± {accuracy_scores.std():.4f}\")\n",
        "    print(f\"  ROC AUC: {roc_auc_scores.mean():.4f} ± {roc_auc_scores.std():.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"El tiempo de entrenamiento fue de {elapsed_time:.2f} segundos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JcsGLeGWrZU",
        "outputId": "a18b2803-49c8-4e87-bda2-72f065bc6332"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "  Accuracy: 0.7178 ± 0.0088\n",
            "  ROC AUC: 0.7928 ± 0.0070\n",
            "El tiempo de entrenamiento fue de 3.17 segundos\n",
            "Random Forest:\n",
            "  Accuracy: 0.7928 ± 0.0077\n",
            "  ROC AUC: 0.8695 ± 0.0064\n",
            "El tiempo de entrenamiento fue de 53.03 segundos\n",
            "KNN:\n",
            "  Accuracy: 0.5921 ± 0.0100\n",
            "  ROC AUC: 0.6207 ± 0.0101\n",
            "El tiempo de entrenamiento fue de 1.60 segundos\n",
            "Naive Bayes:\n",
            "  Accuracy: 0.6640 ± 0.0099\n",
            "  ROC AUC: 0.7446 ± 0.0090\n",
            "El tiempo de entrenamiento fue de 0.10 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- El modelo con las mejores métricas es Random Forest, pero su tiempo de entrenamiento es significativamente mayor que el de los demás modelos. Es importante tener en cuenta este factor."
      ],
      "metadata": {
        "id": "pWfv_dHX_eJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento con Random Forest"
      ],
      "metadata": {
        "id": "0eK8lsMrZUDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datos balanceados"
      ],
      "metadata": {
        "id": "273uSeWb26lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf = train_and_evaluate_model(RandomForestClassifier(random_state=42), X_train_B, y_train_B, X_val_final, y_val_final)"
      ],
      "metadata": {
        "id": "64OPswTY2_E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_importance = rf_clf.feature_importances_\n",
        "\n",
        "# Obtener nombres de las características\n",
        "feature_names = X_train_final.columns\n",
        "\n",
        "# Crear un DataFrame para visualización\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "\n",
        "# Ordenar por importancia de forma descendente\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Visualizar las 10 características más importantes\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(40), palette='viridis')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9r83iXY_DLze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Datos Balanceados con PCA"
      ],
      "metadata": {
        "id": "t9XNiIr53XRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_PCA = train_and_evaluate_model(RandomForestClassifier(random_state=42), X_train_pca_B, y_train_B, X_val_pca_B, y_val_final)"
      ],
      "metadata": {
        "id": "nOqn6murfRg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtener las importancias de las componentes principales del modelo RandomForest\n",
        "feature_importance_pca = rf_clf_PCA.feature_importances_\n",
        "\n",
        "# Obtener las cargas de las características originales en las componentes principales\n",
        "components = pca.components_\n",
        "\n",
        "# Crear un DataFrame para visualización de las cargas de las características originales en las componentes principales\n",
        "component_names = [f\"PC{i+1}\" for i in range(components.shape[0])]\n",
        "feature_names = X_train_final.columns\n",
        "component_df = pd.DataFrame(components, columns=feature_names, index=component_names)\n",
        "\n",
        "# Calcular la importancia relativa de las características originales\n",
        "original_feature_importance = np.abs(component_df.T @ feature_importance_pca)\n",
        "\n",
        "# Crear un DataFrame para visualización de la importancia relativa de las características originales\n",
        "original_feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': original_feature_importance})\n",
        "original_feature_importance_df = original_feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Visualizar las 10 características originales más importantes\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=original_feature_importance_df.head(26), palette='viridis')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Original Feature Importances (After PCA and RandomForest)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0nzgqX3bC7AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento Con Xbgboost"
      ],
      "metadata": {
        "id": "OkcRJ-S7ZbYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "params = {\n",
        "    'eta': 0.0001,\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': ['logloss', 'auc']\n",
        "}\n",
        "train_xgboost_model(X_train_pca_B, y_train_B, X_val_pca_B, y_val_final, params)"
      ],
      "metadata": {
        "id": "l_dhaNUcAQZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-eKi_Op_KOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando *Feature Selection* en el en entrenamiento"
      ],
      "metadata": {
        "id": "orB5hj9K2bHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(col_selected_num) + len(cat_cols_selected)"
      ],
      "metadata": {
        "id": "f4jRFHsHAdCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_selection = X_train_B[col_selected_num + cat_cols_selected]\n",
        "X_val_selection = X_val_final[col_selected_num + cat_cols_selected]\n",
        "rf_clf_selection = train_and_evaluate_model(RandomForestClassifier(random_state=42), X_train_selection, y_train_B, X_val_selection, y_val_final)"
      ],
      "metadata": {
        "id": "7aiYHNZa2jgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_importance = rf_clf_selection .feature_importances_\n",
        "\n",
        "# Obtener nombres de las características\n",
        "feature_names = X_train_selection.columns\n",
        "\n",
        "# Crear un DataFrame para visualización\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "\n",
        "# Ordenar por importancia de forma descendente\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Visualizar las 10 características más importantes\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(40), palette='viridis')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WbKpZ_gMEXkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueSniuMj95e0"
      },
      "source": [
        "Se puede observar que el rendimiento varía según el rango de TransactionAmt tanto para los modelos de Random Forest como para XGBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1au_uTQ95e0"
      },
      "source": [
        "## Conclusión\n",
        "-   Se separaron los datos procesados en conjuntos de entrenamiento, validación y prueba.\n",
        "-   Los datos de entrenamiento fueron balanceados utilizando submuestreo (undersampling).\n",
        "-   Se entrenaron tres modelos diferentes de clasificación supervisada: Logistic Regression, Random Forest y XGBoost, evaluando métricas clave para la clasificación binaria de fraude y no fraude.\n",
        "-   El modelo de Random Forest obtuvo las mejores métricas con un AUC de 0.74, seguido por XGBoost con un AUC de 0.64 y Logistic Regression con un AUC de 0.56. Aunque la exactitud (accuracy) de XGBoost fue mayor que la de Random Forest, el AUC es una métrica más relevante para evaluar la capacidad del modelo para distinguir entre eventos fraudulentos y no fraudulentos.\n",
        "- AUC y Recall: En problemas de fraude, el AUC y el recall de la clase fraudulenta son cruciales. Un alto recall para la clase de fraude significa que el modelo detecta la mayoría de los casos de fraude, lo cual es vital en este contexto.\n",
        "    - Recall (Sensibilidad o Recall):\n",
        "    El recall para la clase \"No Fraude\" es moderado, lo que significa que el modelo identifica correctamente el 73% de los casos de no fraude. Para la clase \"Fraude\", el recall es sorprendentemente alto (0.77), indicando que el modelo detecta una buena cantidad de los casos de fraude, aunque con baja precisión.\n",
        "- Se puede observar que el rendimiento varía según el rango de TransactionAmt tanto para los modelos de Random Forest como para XGBoost.  \n",
        "### Resultados\n",
        "\n",
        "| Modelo              | AUC  | Accuracy |\n",
        "|---------------------|------|----------|\n",
        "| Random Forest       | 0.74 | 0.72     |\n",
        "| XGBoost             | 0.64 | 0.76     |\n",
        "| Logistic Regression | 0.56 | 0.69     |\n",
        "\n",
        "**Nota:** El AUC (Área Bajo la Curva ROC) es especialmente importante en la detección de fraude, ya que mide la capacidad del modelo para separar correctamente las clases de fraude y no fraude. Aunque XGBoost mostró una mayor exactitud, el modelo de Random Forest fue superior en términos de AUC, lo que indica una mejor discriminación entre eventos fraudulentos y no fraudulentos.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}