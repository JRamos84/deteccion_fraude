{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgq71l3nMcl1uBKoJnCe2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JRamos84/deteccion_fraude/blob/main/notebooks/02_Data_Cleaning_and_Preprocessing_selection_feature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Data Cleaning and Preprocessing\n",
        "**Objetivo**: Limpiar y preprocesar los datos para que estén listos para el modelado.\n",
        "**Contenido**:\n",
        "- Manejo de valores nulos.\n",
        "- Creación de nuevas características (feature engineering).\n",
        "- Conversión de tipos de datos.\n",
        "- Codificación de variables categóricas.\n",
        "- Normalización y estandarización de las variables.\n"
      ],
      "metadata": {
        "id": "ha3ahSIYvJeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import datetime\n",
        "import warnings\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "lmeLgll5vql1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    \"\"\"\n",
        "    Reduce el uso de memoria de un DataFrame de pandas cambiando los tipos de datos de las columnas numéricas\n",
        "    a tipos más eficientes sin perder información.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): El DataFrame a optimizar.\n",
        "    verbose (bool): Si es True, imprime el uso de memoria antes y después de la optimización.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: El DataFrame optimizado.\n",
        "    \"\"\"\n",
        "    # Obtener el uso inicial de memoria\n",
        "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "\n",
        "            # Optimización para tipos de datos enteros\n",
        "            if pd.api.types.is_integer_dtype(df[col]):\n",
        "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "\n",
        "            # Optimización para tipos de datos flotantes\n",
        "            else:\n",
        "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    # Obtener el uso final de memoria\n",
        "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    if verbose:\n",
        "        print(f'Mem. usage decreased to {end_mem:.2f} Mb ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "D4ew9EtFvn2g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importamos las librerias a usar\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYgQkCUGvHZ1",
        "outputId": "daa937f9-1f48-48c9-da42-692a81ec37d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Cargamos los dataset de train_transaction y train_identity\n",
        "df_transaction_train = pd.read_csv(data_dir + '/train_transaction.csv')\n",
        "df_identity_train = pd.read_csv(data_dir + '/train_identity.csv')\n",
        "## Reducimos los tamaños de los dataset cambiando los tipos de los datos de las columnas\n",
        "df_transaction_train = reduce_mem_usage(df_transaction_train)\n",
        "df_identity_train = reduce_mem_usage(df_identity_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmCKf4pavhlr",
        "outputId": "0943ac56-0e48-4e0a-f3f1-74c85f5d7abc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mem. usage decreased to 867.89 Mb (58.7% reduction)\n",
            "Mem. usage decreased to 138.38 Mb (12.2% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combinar los datasets\n",
        "data = pd.merge(df_transaction_train, df_identity_train, on='TransactionID', how='left')\n"
      ],
      "metadata": {
        "id": "1tTBpZ94vv_a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = data.copy()"
      ],
      "metadata": {
        "id": "TqhlN02WQ2NR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consideración principales del análisis de EDA"
      ],
      "metadata": {
        "id": "9mdnQAfuv7Sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manejo de valores nulos"
      ],
      "metadata": {
        "id": "MUSl5uZowTwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Usaremos las columnas que no superen el 50 de los valores nulos"
      ],
      "metadata": {
        "id": "QkeZSZ3nwqMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_percentages = (dataset.isnull().sum() / len(dataset)) * 100\n",
        "null_percentages[null_percentages < 50].sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsMt4KlPv19R",
        "outputId": "05d73ee4-4422-4949-dfc5-39139e9865e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M4               47.658753\n",
              "D2               47.549192\n",
              "V1               47.293494\n",
              "V10              47.293494\n",
              "D11              47.293494\n",
              "                   ...    \n",
              "C12               0.000000\n",
              "C13               0.000000\n",
              "C14               0.000000\n",
              "isFraud           0.000000\n",
              "TransactionID     0.000000\n",
              "Length: 220, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_util = null_percentages[null_percentages < 20].index.to_list()"
      ],
      "metadata": {
        "id": "dtNf-tDsxRHR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset[col_util]\n",
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncDgrUhMxcNV",
        "outputId": "6e5c0696-e055-4cdc-b915-84cacc9a8015"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 182)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Eliminamos las filas nulas\n",
        "dataset.dropna(inplace=True)\n",
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG9_vjxgxij-",
        "outputId": "c4d219cb-119a-4a80-c7ca-cde44eb0c776"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(346886, 182)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- La cantidad de registro dismuyo considerablemente luego de la elimación de las columnas y las filas con datos nulos"
      ],
      "metadata": {
        "id": "KDiDJ7zTyFnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rango de TransactionAMT y Aplicación del Logaritmo"
      ],
      "metadata": {
        "id": "kV4nCNkyygzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Basado en el análisis EDA elinamos los registro con valores en TransactionAMT superior a 5192"
      ],
      "metadata": {
        "id": "jt5xmIC2ymcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset[dataset['TransactionAmt'] < 5192]"
      ],
      "metadata": {
        "id": "6GSEYKI3ylgY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['TransactionAmt'] = np.log(dataset['TransactionAmt'])\n"
      ],
      "metadata": {
        "id": "SFzkMdR-2xBt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Convertiendo 'TransactionDT' en unidades de tiempo"
      ],
      "metadata": {
        "id": "k3Gv6x1fzEi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Suponiendo que dataset tiene las columnas 'TransactionDT'\n",
        "START_DATE = '2017-12-01'\n",
        "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
        "\n",
        "# Convertir 'TransactionDT' a formato datetime\n",
        "dataset['Date'] = dataset['TransactionDT'].apply(lambda x: startdate + datetime.timedelta(seconds=x))\n",
        "\n",
        "# Verificar y asegurarse de que 'Date' sea de tipo datetime\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
        "\n",
        "# Crear un DataFrame con las nuevas columnas a agregar\n",
        "new_columns = pd.DataFrame({\n",
        "    '_Weekdays': dataset['Date'].dt.dayofweek,\n",
        "    '_Hours': dataset['Date'].dt.hour,\n",
        "    '_Days': dataset['Date'].dt.day\n",
        "})\n",
        "\n",
        "# Unir todas las columnas al DataFrame original\n",
        "dataset = pd.concat([dataset, new_columns], axis=1)\n",
        "\n",
        "# Convertir las nuevas columnas a tipo 'object' si es necesario\n",
        "dataset['_Weekdays'] = dataset['_Weekdays'].astype('object')\n",
        "dataset['_Hours'] = dataset['_Hours'].astype('object')\n",
        "dataset['_Days'] = dataset['_Days'].astype('object')\n",
        "\n",
        "# Eliminar las columnas innecesarias\n",
        "dataset.drop(['Date', 'TransactionDT'], axis=1, inplace=True)\n",
        "\n",
        "# Mostrar los primeros 3 registros del DataFrame modificado\n",
        "print(dataset.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCXCjMG8zJBr",
        "outputId": "d31757ad-f272-487c-f071-37ba54d30543"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   TransactionID  isFraud  TransactionAmt ProductCD  card1  card2  card3  \\\n",
            "1        2987001        0        3.367188         W   2755  404.0  150.0   \n",
            "2        2987002        0        4.078125         W   4663  490.0  150.0   \n",
            "3        2987003        0        3.912109         W  18132  567.0  150.0   \n",
            "\n",
            "        card4  card5   card6  ...  V315  V316    V317   V318  V319  V320  \\\n",
            "1  mastercard  102.0  credit  ...   0.0   0.0     0.0    0.0   0.0   0.0   \n",
            "2        visa  166.0   debit  ...   0.0   0.0     0.0    0.0   0.0   0.0   \n",
            "3  mastercard  117.0   debit  ...   0.0  50.0  1404.0  790.0   0.0   0.0   \n",
            "\n",
            "   V321  _Weekdays  _Hours  _Days  \n",
            "1   0.0          5       0      2  \n",
            "2   0.0          5       0      2  \n",
            "3   0.0          5       0      2  \n",
            "\n",
            "[3 rows x 184 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping emails"
      ],
      "metadata": {
        "id": "i4_RBzBNz4XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.kaggle.com/code/kabure/extensive-eda-and-modeling-xgb-hyperopt?scriptVersionId=18427966&cellId=116\n",
        "emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum',\n",
        "          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n",
        "          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n",
        "          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft',\n",
        "          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n",
        "          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n",
        "          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft',\n",
        "          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other',\n",
        "          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n",
        "          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n",
        "          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n",
        "          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink',\n",
        "          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other',\n",
        "          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo',\n",
        "          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other',\n",
        "          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other',\n",
        "          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other',\n",
        "          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n",
        "          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n",
        "\n",
        "us_emails = ['gmail', 'net', 'edu']\n",
        "\n",
        "# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100499#latest-579654\n",
        "#for c in ['P_emaildomain', 'R_emaildomain']:\n",
        "for c in ['P_emaildomain']:\n",
        "    dataset[c + '_bin'] = dataset[c].map(emails)\n",
        "    dataset[c + '_suffix'] = dataset[c].map(lambda x: str(x).split('.')[-1])\n",
        "    dataset[c + '_suffix'] = dataset[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
        "\n",
        "## Elimaamos las columnas 'P_emaildomain', 'R_emaildomain'\n",
        "dataset.drop(['P_emaildomain'], axis=1, inplace=True)\n",
        "### IMPORTANTE  'R_emaildomain' fue sacada del analisis debido a que tiene un elavado cantidad de valores nulos\n"
      ],
      "metadata": {
        "id": "wvI7212Bz8jL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separamos datos características (X) y variable objetivo (y)"
      ],
      "metadata": {
        "id": "iR__r4m17fDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.drop('isFraud', axis=1)  # features\n",
        "y = dataset['isFraud']  # target"
      ],
      "metadata": {
        "id": "nJbiGC6o7hMq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## División de los Datos en Conjuntos de Entrenamiento y Prueba"
      ],
      "metadata": {
        "id": "MIwyOaeJhwbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criterios para la División de Datos\n",
        "\n",
        "#### Entrenamiento (Training Set):\n",
        "- Representa el 70% del conjunto de datos.\n",
        "- Se utiliza para ajustar el modelo.\n",
        "\n",
        "#### Validación (Validation Set):\n",
        "- Representa el 15% del conjunto de datos.\n",
        "- Se utiliza para ajustar los hiperparámetros y prevenir el sobreajuste.\n",
        "\n",
        "#### Prueba (Test Set):\n",
        "- Representa el 15% del conjunto de datos.\n",
        "- Se utiliza para evaluar el rendimiento final del modelo.\n"
      ],
      "metadata": {
        "id": "tKw1PQZch2Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOaUcWdtR1BL",
        "outputId": "fb81879c-23b7-43d6-b316-4f299c80377e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((346874, 184), (346874,))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y conjunto temporal (que se dividirá en validación y prueba)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Dividir el conjunto temporal en conjunto de validación y conjunto de prueba\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# Mostrar las formas de los conjuntos de datos para asegurarse de que la estratificación se realizó correctamente\n",
        "print(\"Forma del conjunto de entrenamiento:\", X_train.shape, y_train.shape)\n",
        "print(\"Forma del conjunto de validación:\", X_val.shape, y_val.shape)\n",
        "print(\"Forma del conjunto de prueba:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "9nbOzPQ3hx23",
        "outputId": "b8fefc35-d4d3-4ce3-f23f-2accd77cb8ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma del conjunto de entrenamiento: (242811, 184) (242811,)\n",
            "Forma del conjunto de validación: (52031, 184) (52031,)\n",
            "Forma del conjunto de prueba: (52032, 184) (52032,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()"
      ],
      "metadata": {
        "id": "emJMwt-D4z1L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Codificación de variables categóricas.\n"
      ],
      "metadata": {
        "id": "IZdNX1Ndifpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "metadata": {
        "id": "wu-yJbAKkwye",
        "outputId": "19f053b2-af35-421b-c7b6-0f9c3a7dc516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((242811, 184), (52031, 184), (52032, 184))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.select_dtypes(include=['object']).nunique()"
      ],
      "metadata": {
        "id": "GGQiFZznmulz",
        "outputId": "8f96f87a-80b5-48aa-c4d6-3c9c26849f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProductCD                4\n",
              "card4                    4\n",
              "card6                    3\n",
              "_Weekdays                7\n",
              "_Hours                  24\n",
              "_Days                   31\n",
              "P_emaildomain_bin        9\n",
              "P_emaildomain_suffix     7\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.dtypes"
      ],
      "metadata": {
        "id": "DpT6_zvwXUle",
        "outputId": "ea7d11f4-a156-4012-b171-988b12ca4ef2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransactionID             int32\n",
              "TransactionAmt          float16\n",
              "ProductCD                object\n",
              "card1                     int16\n",
              "card2                   float16\n",
              "                         ...   \n",
              "_Weekdays                object\n",
              "_Hours                   object\n",
              "_Days                    object\n",
              "P_emaildomain_bin        object\n",
              "P_emaildomain_suffix     object\n",
              "Length: 184, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def label_encode_columns(X_train, X_val,X_test,cat_cols):\n",
        "  X_train = X_train.copy()\n",
        "  X_val = X_val.copy()\n",
        "  X_test = X_test.copy()\n",
        "  for col in cat_cols:\n",
        "      #print('aqui')\n",
        "      if X_train[col].dtype=='object' or X_val[col].dtype=='object' or X_test[col].dtype=='object':\n",
        "          #print(col)\n",
        "          lbl = LabelEncoder()\n",
        "          lbl.fit(list(X_train[col].values)+list(X_val[col].values) + list(X_test[col].values))\n",
        "          X_train[col] = lbl.transform(list(X_train[col].values))\n",
        "          X_val[col] = lbl.transform(list(X_val[col].values))\n",
        "          X_test[col] = lbl.transform(list(X_test[col].values))\n",
        "\n",
        "  return X_train,X_val ,X_test,lbl\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# Suponiendo que X_train y X_test son tus DataFrames originales\n",
        "X_train_final, X_val_final  ,X_test_final,label_encoders = label_encode_columns(X_train, X_val,X_test,cat_cols)\n",
        "\n"
      ],
      "metadata": {
        "id": "AmoznGGE1zTo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalización y estandarización de las variables."
      ],
      "metadata": {
        "id": "9FwrNODMijRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_min_max = MinMaxScaler()\n",
        "X_train_final[num_cols] = scaler_min_max.fit_transform(X_train_final[num_cols])\n",
        "X_test_final[num_cols] = scaler_min_max.transform(X_test_final[num_cols])\n",
        "X_val_final[num_cols] = scaler_min_max.transform(X_val_final[num_cols])\n",
        "\n"
      ],
      "metadata": {
        "id": "5VxDYi5T4ag7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uso de la Validación Cruzada para Determinar el Número de Componentes en PCA\n"
      ],
      "metadata": {
        "id": "JCa_gX8QiohK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleccionamos una porción de los datos de entrenamiento para evaluar de manera óptima el modelo y realizar el análisis PCA."
      ],
      "metadata": {
        "id": "cwv2BupAeHW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la fracción del conjunto de datos para preentrenamiento\n",
        "fraction = 0.5  # 10%\n",
        "\n",
        "\n",
        "y = np.ravel(y_train)\n",
        "\n",
        "# Dividir el conjunto de datos para obtener el subconjunto estratificado\n",
        "X_pretrain, _, y_pretrain, _ = train_test_split(X_train_final, y, train_size=fraction, stratify=y, random_state=42)\n",
        "\n",
        "# Verificar las proporciones de las clases\n",
        "print(\"Proporción de clases en el conjunto original:\", np.bincount(y) / len(y))\n",
        "print(\"Proporción de clases en el subconjunto de preentrenamiento:\", np.bincount(y_pretrain) / len(y_pretrain))\n",
        "print(f\"Tamaño del subconjunto de preentrenamiento: {len(y_pretrain)} muestras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ycAZX4geChF",
        "outputId": "6141854b-fbf4-4753-b229-80ef4ea36071"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proporción de clases en el conjunto original: [0.97999267 0.02000733]\n",
            "Proporción de clases en el subconjunto de preentrenamiento: [0.97999259 0.02000741]\n",
            "Tamaño del subconjunto de preentrenamiento: 121405 muestras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Balanceo sin PCA\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_pretrain_B, y_pretrain_B,= undersampler.fit_resample(X_pretrain, y_pretrain)\n",
        "# Mostrar la distribución de clases después del submuestreo\n",
        "X_pretrain_B.shape, y_pretrain_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MomqhxpUdmRw",
        "outputId": "00ba5455-576c-4856-cf05-a5fc4d3eb6c6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4858, 184), (4858,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_pretrain_B, return_counts=True)\n",
        "\n",
        "# Crear un diccionario para mostrar los resultados\n",
        "value_counts = dict(zip(unique, counts))\n",
        "print(value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lbl6yF_dmN9",
        "outputId": "29925383-a3d5-4f96-9901-e01611352dde"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 2429, 1: 2429}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicia el cronómetro\n",
        "\n",
        "# Número máximo de componentes principales (puede ser el número de características)\n",
        "#max_components = X_pretrain.shape[1]\n",
        "max_components = 50\n",
        "# Inicializar la validación cruzada estratificada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Inicializar el modelo de clasificación\n",
        "classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Array para almacenar los scores de validación cruzada\n",
        "cv_scores = []\n",
        "\n",
        "# Realizar PCA y validación cruzada para diferentes números de componentes\n",
        "for n_components in range(1, max_components + 1):\n",
        "    #start_time = time.time()\n",
        "    # Aplicar PCA\n",
        "\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_pca = pca.fit_transform(X_pretrain_B)\n",
        "\n",
        "    # Evaluar el modelo con validación cruzada\n",
        "    scores = cross_val_score(classifier, X_pca, np.ravel(y_pretrain_B), cv=cv, scoring='accuracy')\n",
        "\n",
        "    # Guardar el promedio de los scores\n",
        "    cv_scores.append(scores.mean())\n",
        "    # print(f'PCA con {n_components} componentes')\n",
        "    # print(f'Accuracy promedio: {scores.mean():.4f} ± {scores.std():.4f}')\n",
        "    # end_time = time.time()\n",
        "    # elapsed_time = end_time - start_time\n",
        "    # print(f\"El tiempo de entrenamiento fue de {elapsed_time:.2f} segundos\")\n",
        "\n",
        "# Determinar el número óptimo de componentes\n",
        "optimal_components = np.argmax(cv_scores) + 1\n",
        "optimal_scores_mean = cv_scores[optimal_components - 1]  # Aquí se ajusta correctamente el índice\n",
        "print(f'Número óptimo de componentes: {optimal_components}')\n",
        "print(f'Score de validación cruzada con {optimal_components} componentes: {cv_scores[optimal_components - 1]}')\n",
        "print(f'Accuracy promedio: {optimal_scores_mean:.4f}')\n",
        "\n",
        "# Graficar los scores de validación cruzada\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, max_components + 1), cv_scores, marker='o', linestyle='--')\n",
        "plt.xlabel('Número de Componentes')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validación Cruzada para PCA y Clasificación Binaria')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "AjCm1J2DdiBr",
        "outputId": "71f98bc8-17bf-4a03-8c0e-7d2688d14eaf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-6742e6768650>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Evaluar el modelo con validación cruzada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pretrain_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Guardar el promedio de los scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing con PCA"
      ],
      "metadata": {
        "id": "UF39DWdyefmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Balanceo de X_train y y_train totales\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_B, y_train_B,= undersampler.fit_resample(X_train_final, y_train)\n",
        "# Mostrar la distribución de clases después del submuestreo\n",
        "X_train_B.shape, y_train_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mLz4lbfeY8D",
        "outputId": "ed0698f9-461b-44ea-94a8-137a19e305e2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9716, 184), (9716,))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_B, return_counts=True)\n",
        "\n",
        "# Crear un diccionario para mostrar los resultados\n",
        "value_counts = dict(zip(unique, counts))\n",
        "print(value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqI40nZRenBc",
        "outputId": "17d3d8ca-24ef-4218-f0bb-6d0436bc1f01"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 4858, 1: 4858}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Balanceo y pca\n",
        "\n",
        "pca = PCA(n_components=26)\n",
        "X_train_pca_B = pca.fit_transform(X_train_B)\n",
        "\n"
      ],
      "metadata": {
        "id": "W9F5Wlq6eqgX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportar preprocesamiento"
      ],
      "metadata": {
        "id": "oDHV-nO4hTBI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFkKdauNie0T"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dir_data_preprocessing='/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection/preprocessing_objects'\n",
        "ruta_archivo_encoder = os.path.join(dir_data_preprocessing, 'label_encoders.joblib')\n",
        "ruta_archivo_scaler = os.path.join(dir_data_preprocessing, 'scaler_min_max.joblib')\n",
        "ruta_archivo_pca = os.path.join(dir_data_preprocessing, 'pca.joblib')\n",
        "\n",
        "\n",
        "joblib.dump(label_encoders, ruta_archivo_encoder)\n",
        "joblib.dump(scaler_min_max,ruta_archivo_scaler)\n",
        "joblib.dump(pca, ruta_archivo_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63D4nIppf-ai",
        "outputId": "18137573-ef43-4766-874d-1b4283e9c508"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection/preprocessing_objects/pca.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Se probó ajustando el porcentaje de valores permitidos por columna para maximizar la cantidad de columnas utilizadas en el análisis de componentes principales (PCA). Los resultados mostraron que el número máximo de componentes principales (PCA) obtenidos es de 4 cuando se permiten columnas con hasta un 20% de valores faltantes:\n",
        "\n",
        "- Columnas con menos del 10% de valores faltantes: 3 componentes\n",
        "- Columnas con menos del 20% de valores faltantes: 4 componentes\n",
        "- Columnas con menos del 50% de valores faltantes: 4 componentes\n",
        "- Columnas con menos del 60% de valores faltantes: 4 componentes\n",
        "\n",
        "Se observó que la máxima varianza se logra con un número reducido de componentes principales, lo cual indica que gran parte de la información se puede capturar eficientemente con pocos componentes.\n",
        "\n",
        "Por lo tanto vamos a trabajas con columnas que no tengan más del 20 de valores nulos."
      ],
      "metadata": {
        "id": "S7eRVl5qStFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar X y y en archivos CSV\n",
        "\n",
        "#dir_data_processed = '../data/processed'\n",
        "dir_data_processed = '/content/drive/MyDrive/cursos-analisis-datos/data-science/proyecto/propuestas/propuesta1/ieee-fraud-detection/processed'\n",
        "ruta_archivo_X_train = os.path.join(dir_data_processed, 'X__train_procesados.csv')\n",
        "ruta_archivo_X_test = os.path.join(dir_data_processed, 'X_test_procesados.csv')\n",
        "ruta_archivo_X_val = os.path.join(dir_data_processed, 'X_val_procesados.csv')\n",
        "\n",
        "ruta_archivo_y_train = os.path.join(dir_data_processed, 'y_train_procesados.csv')\n",
        "ruta_archivo_y_test = os.path.join(dir_data_processed, 'y_test_procesados.csv')\n",
        "ruta_archivo_y_val = os.path.join(dir_data_processed, 'y_val_procesados.csv')\n",
        "\n",
        "\n",
        "X_train_final.to_csv(ruta_archivo_X_train, index=False, encoding='utf-8')\n",
        "X_val_final.to_csv(ruta_archivo_X_val, index=False, encoding='utf-8')\n",
        "X_test_final.to_csv(ruta_archivo_X_test, index=False, encoding='utf-8')\n",
        "\n",
        "y_train.to_csv(ruta_archivo_y_train, index=False, encoding='utf-8')\n",
        "y_val.to_csv(ruta_archivo_y_val, index=False, encoding='utf-8')\n",
        "y_test.to_csv(ruta_archivo_y_test, index=False, encoding='utf-8')\n",
        "\n"
      ],
      "metadata": {
        "id": "IIZFPqz38eNG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "xklfde6BwqFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6d30c8-1315-41b3-a911-f30d872bfd94"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242811,)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}